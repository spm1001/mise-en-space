{"id": "mise-02b", "title": "Integration test with real account", "type": "action", "status": "done", "done_at": "2026-01-25T16:41:13.180683Z", "brief": {"why": "End-to-end test: search → fetch → read file. Uses test fixtures from V2.md.", "what": "## Test Fixtures (from EXPERIMENTS.md)\n\n| Fixture | ID | Description |\n|---------|-----|-------------|\n| Doc: Simple | 1w8KcJtwlHcWn3HLlp9QVMQzmfVegW0lhVOd8K8kuLig | ROUNDTRIP_TEST |\n| Doc: Multi-tab | 1vqkOoNbPuc1MNolYZRhKvBONGZrrIopAb7bzYzn5x0k | Team Handbook |\n| Sheets | 1Hf2smDVDjBlxaZuGZvAJML5XmdFM-sPZW3xkCRfUfLY | Team meeting |\n| Gmail: Long thread | 194ac68f6091de54 | 72 messages |\n\n## Test Cases\n\n1. search(\"budget\") → returns Drive + Gmail results\n2. fetch(doc_id) → writes markdown, returns path\n3. fetch(sheet_id) → writes CSV, returns path\n4. fetch(thread_id) → writes cleaned text, returns path\n5. Read returned path → content is valid\n\n## Acceptance Criteria\n\n- [ ] All fixture types tested\n- [ ] Paths exist and readable\n- [ ] Content is valid markdown/CSV/text\n- [ ] No inline content in MCP response", "done": "When complete"}, "created_at": "2026-01-23T07:25:46.343318Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-067", "title": "Enable Claude to access browser dev tools directly", "type": "action", "status": "done", "brief": {"why": "Claude needs to sniff network requests autonomously, not via human-in-the-loop. Explore: webctl network intercept, Playwright request/response events, or Anthropic's claude-in-chrome extension.", "what": "## Problem\n\nReverse-engineering private APIs requires inspecting network traffic. Currently:\n- User opens DevTools manually\n- User copies requests\n- Claude interprets\n- Slow, error-prone, breaks flow\n\n## Options\n\n1. **webctl enhancement**: Add `webctl intercept` command that captures requests/responses\n   - Playwright has `page.on('request')`, `page.on('response')`\n   - Could filter by URL pattern\n   - Return as JSON for Claude to parse\n\n2. **claude-in-chrome**: Anthropic's extension at ~/Repos/ (check if exists)\n   - May already have DevTools integration\n   - Native to Claude's ecosystem\n\n3. **Playwright directly**: Write a Python script that launches browser + intercepts\n   - More control, but heavier lift\n\n## Acceptance Criteria\n\n- [ ] Claude can autonomously capture network requests\n- [ ] Filter by URL pattern (e.g., \"timedtext\", \"gemini\")\n- [ ] Get request headers, payload, response body\n- [ ] No human copy-paste required", "done": "When complete"}, "created_at": "2026-01-24T08:54:12.814936Z", "created_by": "spm1001", "order": 1, "parent": "mise-jy3", "waiting_for": null, "done_at": "2026-01-29T20:47:52Z"}
{"id": "mise-138", "title": "Push to GitHub as mise-en-space", "type": "action", "status": "done", "brief": {"why": "Create GitHub repo, push initial scaffold. Currently local-only.", "what": "See title", "done": "When complete"}, "created_at": "2026-01-20T22:10:42.331554Z", "created_by": "spm1001", "order": 1, "waiting_for": null, "done_at": "2026-01-31T19:52:09Z"}
{"id": "mise-1k9", "title": "Slides adapter: batch thumbnails", "type": "action", "status": "done", "done_at": "2026-01-23T18:04:15.647345Z", "brief": {"why": "Wire presentations().get() + batch pages().getThumbnail() to extractor and workspace. Use timing from scripts/slides_timing.py as reference.", "what": "See title", "done": "When complete"}, "created_at": "2026-01-23T17:31:15.20764Z", "created_by": "spm1001", "order": 1, "waiting_for": null}
{"id": "mise-2bl", "title": "Port slides extractor", "type": "action", "status": "done", "done_at": "2026-01-23T17:26:59.130711Z", "brief": {"why": "Port slides.py extraction (658 lines). Structured text + speaker notes, visual flags.", "what": "## What to Port\n\nFrom v1 tools/slides.py:\n- Text extraction per slide\n- Speaker notes\n- Visual flags: [CHART], [IMAGE], [CONNECTOR], [SHAPE]\n- Detection: single_large_image, fragmented_text\n\n## NOT Porting (for now)\n\n- Thumbnail generation (~1s per thumbnail, bottleneck)\n- Can add later if needed\n- **When added: thumbnails MUST use batch API** — `new_batch_http_request()` for selected slides, not per-slide calls\n\n## Signature\n\nextract_slides(presentation_response: dict) -> str\n\n## Acceptance Criteria\n\n- [ ] extractors/slides.py exists\n- [ ] Text + speaker notes extracted\n- [ ] Visual flags present\n- [ ] No thumbnail dependency\n- [ ] Unit test with fixture passes", "done": "When complete"}, "created_at": "2026-01-23T07:24:35.46529Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-2h2", "title": "Handle rowSpan in table parsing", "type": "action", "status": "done", "done_at": "2026-01-24T22:06:37.079881Z", "brief": {"why": "Slides tables can have merged cells with rowSpan > 1. Currently only colSpan is handled. Without rowSpan handling, vertically merged cells produce silently wrong output — a 'silent killer' that corrupts data without warning.", "what": "See title", "done": "When complete"}, "created_at": "2026-01-23T17:31:16.750633Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-2jz", "title": "Save sanitized real doc fixture", "type": "action", "status": "done", "done_at": "2026-01-23T15:47:44.399211Z", "brief": {"why": "User's test doc (1z-nQAcKlgortu22NbcL8ov9EfshWKabCFON3h-KYruQ) has linked slides, linked charts, linked tables, multiple tabs. Perfect test case. Sanitize and save as fixtures/docs/real_multi_tab.json for regression testing.", "what": "See title", "done": "When complete"}, "created_at": "2026-01-23T14:50:13.983104Z", "created_by": "spm1001", "order": 1, "waiting_for": null}
{"id": "mise-356", "title": "Port docs extractor", "type": "action", "status": "done", "done_at": "2026-01-23T13:15:19.926008Z", "brief": {"why": "Port docs.py extraction logic (661 lines). Handles multi-tab, footnotes, link merging.", "what": "## What to Port\n\nFrom v1 tools/docs.py:\n- Multi-tab document handling\n- Footnote extraction\n- Hyperlink merging (adjacent runs)\n- Heading/list hierarchy\n- Table extraction\n\n## Signature\n\nextract_doc(doc_response: dict) -> str\n\nInput: Raw Docs API documents.get() response\nOutput: Markdown string\n\n## Acceptance Criteria\n\n- [ ] extractors/docs.py exists\n- [ ] Handles multi-tab with === Tab: Name === separators\n- [ ] Preserves footnotes, links, tables\n- [ ] Unit test with fixture passes", "done": "When complete"}, "created_at": "2026-01-23T07:24:20.419125Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-3ab", "title": "Wire create tool", "type": "action", "status": "done", "done_at": "2026-01-24T20:22:11.242796Z", "brief": {"why": "Create Google Doc/Sheet/Slides from markdown. Secondary priority.", "what": "## Signature\n\ncreate(content: str, title: str, doc_type: str = 'doc', folder_id: str = None) -> dict\n\n## Response Shape\n\n{\n  \"file_id\": \"...\",\n  \"url\": \"https://docs.google.com/...\",\n  \"title\": \"...\",\n  \"type\": \"doc|sheet|slides\"\n}\n\n## Current State\n\nserver.py:100 has:\n```python\n# TODO: Wire to tools/create.py\nreturn {\"status\": \"not_implemented\", \"title\": title}\n```\n\nNo tools/create.py exists yet.\n\n## Implementation Approach\n\n### 1. Drive Native Markdown Import (Docs)\n\nUse Drive's native markdown import (discovered via about.get):\n```python\nfile_metadata = {\n    'name': title,\n    'mimeType': 'application/vnd.google-apps.document',\n    'parents': [folder_id] if folder_id else []\n}\nmedia = MediaIoBaseUpload(\n    io.BytesIO(content.encode()),\n    mimetype='text/markdown'\n)\nfile = service.files().create(\n    body=file_metadata, \n    media_body=media,\n    fields='id,webViewLink'\n).execute()\n```\n\n### 2. Sheets from CSV/TSV\n\nFor doc_type='sheet':\n- Parse markdown tables → CSV\n- Upload with mimeType text/csv → converts to Sheet\n- Or: Create empty sheet, populate via Sheets API (more control)\n\n### 3. Slides from Markdown\n\nFor doc_type='slides':\n- Parse markdown headings as slides\n- Use Slides API to create presentation\n- Or: Create from template with placeholder replacement\n\n## File Structure\n\n```\ntools/\n  create.py         # Tool implementation\nadapters/\n  create.py         # Drive create operations (if needed)\n```\n\n## Acceptance Criteria\n\n- [ ] tools/create.py exists\n- [ ] server.py wires create() to tool\n- [ ] Creates Google Doc from markdown\n- [ ] Returns file_id and webViewLink\n- [ ] Optional folder_id parameter works\n- [ ] Error handling for invalid content\n- [ ] Integration test creates real doc", "done": "When complete"}, "created_at": "2026-01-23T07:25:22.84022Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-3uu", "title": "Confident deployability via comprehensive test coverage", "type": "outcome", "status": "done", "brief": {"why": "Testing infrastructure. Can refactor without fear, CI catches regressions, edge cases covered.", "what": "## Success Criteria\n\n- [ ] Integration tests run against real account\n- [ ] Negative path tests cover malformed input\n- [ ] Adapter mocking infrastructure enables unit testing\n- [ ] Real fixtures captured and sanitized\n- [ ] Warning behaviors tested systematically\n- [ ] Retry decorator behavior verified\n\n## Execution Order\n\n1. **mise-h6m** Adapter mocking infrastructure (enables all other tests)\n2. **mise-02b** Integration test with real account (baseline)\n3. **mise-eqi** Add negative path tests (resilience)\n4. **mise-bl9** Round-trip extractor tests with real fixtures\n5. **mise-5kj** Sanitized test fixtures\n6. **mise-679** Capture linked-content doc fixture\n7. **mise-8g5** Test warning behaviors systematically\n8. **mise-52d.1** Test retry decorator\n9. **mise-qa6** Test hybrid PDF threshold logic\n10. **mise-e5o** Create pre-exfil test fixture\n\n## Why This Matters\n\nWithout tests, every change is a gamble. With comprehensive coverage, can ship with confidence. Mocking infrastructure is the foundation.", "done": "When complete"}, "created_at": "2026-01-24T20:16:45.38323Z", "created_by": "spm1001", "order": 2, "done_at": "2026-02-09T11:56:38Z"}
{"id": "mise-3uu.1", "title": "Gmail body round-trip tests", "type": "action", "status": "done", "brief": {"why": "The real_gmail_thread fixture stores raw API format (base64 bodies in payload). conftest.py extracts headers but leaves body_text/body_html as None. We test header extraction but not actual body extraction on real data. Either: (1) enhance fixture loading to parse bodies, or (2) capture a new fixture with pre-extracted bodies.", "what": "See title", "done": "When complete"}, "created_at": "2026-01-25T17:43:01.90871Z", "created_by": "spm1001", "order": 1, "parent": "mise-3uu", "waiting_for": null, "tactical": {"steps": ["Check what existing adapter tests assert about bodies", "Wire parse_message_payload into real_gmail_thread conftest loader", "Add round-trip tests: real payload → _build_message → decoded bodies", "Add round-trip tests: decoded bodies → extract_message_content → content string", "Verify all existing tests still pass"], "current": 5}, "done_at": "2026-02-09T09:08:04Z"}
{"id": "mise-3uu.2", "title": "Adapter integration tests — verify retry wiring", "type": "action", "status": "done", "brief": {"why": "Current retry tests mock everything. No test verifies that adapters actually use @with_retry correctly. Add thin integration tests (can use mocked services) that verify: (1) an adapter function is decorated, (2) retryable errors trigger retry, (3) non-retryable errors fail immediately. Catches wiring bugs where decorator is forgotten or misconfigured.", "what": "See title", "done": "When complete"}, "created_at": "2026-01-25T17:43:03.471932Z", "created_by": "spm1001", "order": 2, "parent": "mise-3uu", "waiting_for": null, "done_at": "2026-02-09T07:05:05Z"}
{"id": "mise-3xr", "title": "Implement MCP Resources for self-documentation", "type": "action", "status": "done", "done_at": "2026-01-25T17:13:35.99957Z", "brief": {"why": "User expected auto-generated docs via MCP resources. CLAUDE.md says 'Documentation via MCP Resources, not a tool' but no resources are registered in server.py.", "what": "## What MCP Resources Are\nMCP Resources expose read-only content to Claude. Perfect for:\n- Tool documentation\n- Usage examples\n- API patterns\n\n## Implementation\n```python\n@mcp.resource(\"mise://docs/search\")\ndef search_docs():\n    return \"Search tool documentation...\"\n```\n\n## Auto-generation Idea\nCould generate resources from docstrings:\n- Extract tool docstrings at startup\n- Register as resources\n- Claude can read them on demand\n\n## Acceptance Criteria\n- [ ] At least one resource registered\n- [ ] Resource content is useful\n- [ ] Consider auto-generation from docstrings", "done": "When complete"}, "created_at": "2026-01-25T16:59:50.617989Z", "created_by": "spm1001", "order": 1, "waiting_for": null}
{"id": "mise-40q", "title": "Add unit tests for charts adapter", "type": "action", "status": "done", "brief": {"why": "Add mocked unit tests for adapters/charts.py. Currently only integration tested via test_chart_fetch.py. Should test: get_charts_from_spreadsheet() parsing, render_charts_as_pngs() with mocked Slides/Drive services, error handling (missing contentUrl, failed PNG fetch).", "what": "See title", "done": "When complete"}, "created_at": "2026-01-25T20:49:21.043712Z", "created_by": "spm1001", "order": 1, "waiting_for": null, "done_at": "2026-01-29T20:55:36Z"}
{"id": "mise-4h4", "title": "Extraction logic is testable and maintainable", "type": "outcome", "status": "done", "done_at": "2026-01-24T20:34:40.814005Z", "brief": {"why": "Architecture quality. Adapters are pure, can be unit tested without API calls. DRY, clean separation.", "what": "## Success Criteria\n\n- [ ] PDF extraction in adapters/pdf.py (not fetch.py)\n- [ ] Office extraction in adapters/office.py (not fetch.py)\n- [ ] Shared Drive conversion logic factored out\n- [ ] Retry decorator has no duplication\n- [ ] Each adapter testable with mocked responses\n\n## Execution Order\n\n1. **mise-k6g** Factor PDF extraction into adapter\n2. **mise-gtg** Factor Office extraction into adapter\n   (These share Drive conversion - do together, factor shared code)\n3. **mise-v79** Refactor retry decorator duplication\n\n## Why This Matters\n\nHardcoded logic in tools layer = untestable. Can't verify PDF threshold logic without calling real APIs. Clean adapters = confident refactoring.", "done": "When complete"}, "created_at": "2026-01-24T20:16:35.215186Z", "created_by": "spm1001", "order": 2}
{"id": "mise-4mj", "title": "Gmail attachment content in fetch", "type": "outcome", "status": "done", "brief": {"why": "Gmail threads have PDF/image attachments. Pre-exfil detection is wired in, but fetch doesn't yet surface the extracted content — it knows attachments exist in Drive but doesn't include them in the deposit.", "what": "1. Single-attachment fetch API (lahero) 2. Embed extracted PDF content in content.md (voSovu) 3. Integration test for attachment extraction (gifiku) 4. Investigate pre-exfil filename matching robustness (rosite)", "done": "Gmail fetch with PDF attachments deposits attachment content inline in content.md. Integration test proves the round-trip."}, "created_at": "2026-01-25T19:14:31.687721Z", "created_by": "spm1001", "order": 3, "done_at": "2026-02-09T06:40:09Z"}
{"id": "mise-4mj.1", "title": "Pre-exfil folder should be configurable", "type": "action", "status": "done", "brief": {"why": "Pre-exfil detection assumes folder named 'Email Attachments'. Should be configurable via env var or discover by name. If folder doesn't exist or can't be found, skip pre-exfil check gracefully.", "what": "## Config options\n1. MISE_EMAIL_ATTACHMENTS_FOLDER_ID env var (explicit)\n2. Search by name \"Email Attachments\" (auto-discover)\n3. Both: try env var first, fall back to name search\n\n## Graceful degradation\nIf folder not found → skip pre-exfil, download from Gmail\nDon't fail the fetch, just miss the optimization", "done": "When complete"}, "created_at": "2026-01-25T19:18:21.077203Z", "created_by": "spm1001", "order": 1, "parent": "mise-4mj", "waiting_for": null, "done_at": "2026-01-29T23:25:38Z"}
{"id": "mise-52d", "title": "mise-en-space MVP — search + fetch that works", "type": "outcome", "status": "done", "done_at": "2026-01-24T20:18:20.726508Z", "brief": {"why": "Opinionated Google Workspace MCP with 4 verbs: search, fetch, create, help. Filesystem-first, token-efficient, ergonomic for Claude.", "what": "## Core Opinions\n\n1. **4 verbs** — search, fetch, create, help (not 17 tools)\n2. **Filesystem-first** — fetch returns path, Claude reads with standard tools\n3. **Auto-detect IDs** — Gmail/Drive IDs detected, URLs converted\n4. **Always LLM-analysis** — no purpose parameter, always markdown/CSV\n5. **Internal batching** — Gmail batch API under the hood\n6. **Pre-exfil detection** — check \"Email Attachments\" folder first\n\n## Architecture\n\n```\nextractors/   Pure functions (API response → content)\nadapters/     Thin Google API wrappers\ntools/        MCP tool definitions\nworkspace/    File deposit management\n```\n\n## Acceptance Criteria\n\n- [ ] search(query, sources) returns metadata for Drive + Gmail\n- [ ] fetch(id) deposits file, returns path\n- [ ] create(content, title) makes Google Doc from markdown\n- [ ] help() self-documents\n- [ ] Pre-exfiltrated attachments detected and used\n- [ ] Can replace v1 in claude.json", "done": "When complete"}, "created_at": "2026-01-23T07:24:03.211479Z", "created_by": "spm1001", "order": 2}
{"id": "mise-52d.1", "title": "Test retry decorator", "type": "action", "status": "done", "done_at": "2026-01-25T17:38:13.043508Z", "brief": {"why": "Zero coverage on core infrastructure. Write tests for _get_http_status, _should_retry, _convert_to_mise_error, and the decorator itself with both sync and async functions.", "what": "See title", "done": "When complete"}, "created_at": "2026-01-23T09:03:34.812391Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-52d.2", "title": "Add Makefile with check target", "type": "action", "status": "open", "brief": {"why": "make check runs pytest + mypy in one command. Consolidates quality gates.", "what": "## What\n\nSingle command to run all quality gates:\n```bash\nmake check  # runs pytest + mypy\n```\n\n## Implementation\n\n```makefile\n.PHONY: check test lint\n\ncheck: test lint\n\ntest:\n\tuv run pytest tests/unit/ -q\n\nlint:\n\tuv run mypy models.py extractors/ adapters/ validation.py workspace/\n```\n\n## Acceptance Criteria\n\n- [ ] Makefile exists at repo root\n- [ ] `make check` runs tests and mypy\n- [ ] Exit code is non-zero if either fails", "done": "When complete"}, "created_at": "2026-01-23T09:03:46.345057Z", "created_by": "spm1001", "order": 2, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-52d.3", "title": "Add search_threads to gmail adapter", "type": "action", "status": "done", "done_at": "2026-01-23T22:10:53.876656Z", "brief": {"why": "Gmail adapter has fetch_thread and fetch_message but no search. Needed for mise-e0e (Wire search tool).", "what": "See title", "done": "When complete"}, "created_at": "2026-01-23T21:59:43.543047Z", "created_by": "spm1001", "order": 3, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-52d.4", "title": "Pre-exfil attachment detection", "type": "action", "status": "open", "brief": {"why": "When fetching Gmail threads with attachments, check Drive's 'Email Attachments' folder first. Use Drive copy if found (already indexed by fullText search).", "what": "## Why\n\nDrive indexes PDF content via fullText. Gmail doesn't search inside attachments.\nBackground extractor saves attachments to Drive → they become searchable.\nFetch should use the indexed copy when available.\n\n## Approach\n\n1. Config for Email Attachments folder ID (env var or discover by name)\n2. When processing Gmail attachment, query Drive:\n   `'{folder_id}' in parents and name = '{filename}'`\n3. If found, return Drive file_id instead of downloading from Gmail\n4. If not found, fall back to Gmail attachment download\n\n## Edge cases\n\n- Duplicate filenames (same name, different emails) — may need date matching\n- Stale copies (attachment updated, Drive copy old) — probably rare\n- Folder doesn't exist — graceful fallback\n\n## Acceptance Criteria\n\n- [ ] Looks up attachments in configured Drive folder\n- [ ] Uses Drive copy when found\n- [ ] Falls back to Gmail when not found\n- [ ] Works when folder not configured (skip lookup)", "done": "When complete"}, "created_at": "2026-01-23T22:20:19.27301Z", "created_by": "spm1001", "order": 4, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-52d.5", "title": "Support PDF files in fetch", "type": "action", "status": "done", "done_at": "2026-01-24T17:11:55.843775Z", "brief": {"why": "fetch() should handle PDF files using markitdown for text extraction. Drive conversion doesn't help here (PDFs stay as PDFs).", "what": "## Approach\n\n1. Detect PDF MIME type in fetch_drive()\n2. Download file via Drive API\n3. Run through markitdown\n4. Deposit as markdown\n\n## Reference\n\nmarkitdown chosen over PyMuPDF: MIT licensed vs AGPL.\n\n## Acceptance Criteria\n\n- [ ] PDF files extract to markdown via markitdown\n- [ ] Handle multi-page PDFs\n- [ ] Graceful fallback for scanned/image PDFs\n- [ ] Integration test with real PDF", "done": "When complete"}, "created_at": "2026-01-23T23:08:29.79669Z", "created_by": "spm1001", "order": 5, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-52d.6", "title": "Selective thumbnail fetching for slides", "type": "action", "status": "done", "done_at": "2026-01-24T22:21:48.938603Z", "brief": {"why": "Port v1's selective thumbnail logic. Skip stock photos and text-only slides. Reduces 43-slide deck from 20s to ~5s.", "what": "## Problem\n\nSequential thumbnail API calls: ~0.5s each (unavoidable, batch disabled).\n43-slide deck = 20+ seconds blocking.\n\n## v1 Logic (mcp-google-workspace)\n\nLocation: workspace_mcp/tools/slides.py lines 209-239, 562-589\n\nSkip thumbnails when:\n- single_large_image: >50% slide coverage = stock photo\n- text_only: No images, just text shapes\n- empty: No content\n\nOnly thumbnail:\n- Charts, diagrams\n- Fragmented layouts (multiple images/shapes)\n- Complex visual content\n\n## Approach\n\n1. Analyze slide content before fetching thumbnails\n2. Classify each slide: needs_thumbnail | skip\n3. Only fetch for needs_thumbnail slides\n4. Include skip reason in manifest\n\n## Acceptance Criteria\n\n- [ ] Classify slides by visual complexity\n- [ ] Skip single_large_image slides\n- [ ] Skip text_only slides\n- [ ] Manifest shows which slides were skipped and why\n- [ ] Timing improvement measurable (scripts/slides_timing.py)", "done": "When complete"}, "created_at": "2026-01-23T23:08:42.923276Z", "created_by": "spm1001", "order": 6, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-52d.7", "title": "Support Office files in fetch (DOCX, XLSX, PPTX)", "type": "action", "status": "done", "done_at": "2026-01-24T17:24:43.904977Z", "brief": {"why": "fetch() should handle Office files using Drive API conversion (not markitdown). Bakeoff showed Drive conversion is 29% smaller and cleaner.", "what": "## Approach\n\n1. Detect Office MIME types in fetch_drive()\n2. Use Drive API export to convert:\n   - DOCX → text/markdown or text/plain\n   - XLSX → text/csv\n   - PPTX → text/plain (or markdown if available)\n3. Deposit converted content\n\n## Why Drive conversion?\n\nBakeoff (Jan 2026): Drive conversion beats markitdown for Office files.\n- 29% smaller output\n- Cleaner formatting\n- No external dependency\n\n## Acceptance Criteria\n\n- [ ] DOCX files convert via Drive API\n- [ ] XLSX files convert to CSV\n- [ ] PPTX files convert to text\n- [ ] Integration test for each type", "done": "When complete"}, "created_at": "2026-01-24T10:50:23.340289Z", "created_by": "spm1001", "order": 7, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-52d.8", "title": "Support video/audio summaries in fetch", "type": "action", "status": "done", "done_at": "2026-01-24T11:18:30.527307Z", "brief": {"why": "fetch() should return Google's pre-computed AI summaries for video/audio files, rather than just the raw file. Leverages GenAI API discovered via reverse engineering.", "what": "## Approach\n\nUse Google's internal GenAI API (appsgenaiserver-pa.clients6.google.com) to get:\n- AI-generated summary\n- Transcript snippets\n- Suggested prompts\n\n## Reference\n\nFull implementation: ~/Repos/skill-chrome-log/references/DRIVE_VIDEO_SUMMARY_HOWTO.md\n\n## Open Questions\n\n1. **SAPISID cookie**: The API requires browser cookies, not OAuth tokens.\n   Options: webctl, manual, or find alternative auth path.\n\n2. **timedtext endpoint**: Separate /timedtext?fmt=json3 endpoint exists for\n   raw transcripts. May not be needed if summary API returns transcript snippets.\n\n## Acceptance Criteria\n\n- [ ] Solve SAPISID authentication problem\n- [ ] Call GenAI streamGenerate endpoint\n- [ ] Extract summary text from streaming response\n- [ ] Deposit summary + transcript to mise-fetch/\n- [ ] Handle videos without summaries gracefully", "done": "When complete"}, "created_at": "2026-01-24T10:50:24.743143Z", "created_by": "spm1001", "order": 8, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-5kj", "title": "Sanitized test fixtures", "type": "action", "status": "open", "brief": {"why": "Test fixtures contain real data (ITV budget figures, email addresses). Create sanitized versions with fake data that preserves structure. Required before open-sourcing or sharing.", "what": "See title", "done": "When complete"}, "created_at": "2026-01-23T18:04:02.022456Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-626", "title": "Verify linked-content fixture has edge cases", "type": "action", "status": "done", "done_at": "2026-01-25T18:22:19.64487Z", "brief": {"why": "Doc 1bREiVmvgSsRKJLjamTOE0Wasq1ze7R3bIPOdtJMomKM should contain linked slides, linked charts, linked tables. Fetch it and confirm the edge cases exist before relying on it for testing. URL from user: https://docs.google.com/document/d/1bREiVmvgSsRKJLjamTOE0Wasq1ze7R3bIPOdtJMomKM", "what": "See title", "done": "When complete"}, "created_at": "2026-01-23T18:07:57.340642Z", "created_by": "spm1001", "order": 1, "parent": "mise-3uu", "waiting_for": null}
{"id": "mise-679", "title": "Capture linked-content doc fixture", "type": "action", "status": "done", "done_at": "2026-01-25T18:22:20.567657Z", "brief": {"why": "Capture fixture from https://docs.google.com/document/d/1bREiVmvgSsRKJLjamTOE0Wasq1ze7R3bIPOdtJMomKM — contains linked slides, linked charts, linked tables. Test that extractor handles linkedContentReference edge cases correctly.", "what": "## Approach\n\n1. Verify the doc still exists and has linked content\n2. Add to TEST_IDS in capture_fixtures.py\n3. Capture as fixtures/docs/real_linked_content.json\n4. Add test that verifies linked chart/slide placeholders appear\n\n## Why this matters\nCurrent real_multi_tab.json may not have linked content. The docs extractor has special handling for linkedContentReference that needs real-world testing.", "done": "When complete"}, "created_at": "2026-01-23T15:49:05.83736Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-6bo", "title": "Workspace manager — file deposit", "type": "action", "status": "done", "done_at": "2026-01-23T22:28:29.949174Z", "brief": {"why": "Manages ~/.mcp-workspace/ folder structure. Creates paths, cleans temp, returns paths.", "what": "## Structure\n\n~/.mcp-workspace/\n├── [account@domain.com]/\n│   ├── drive/{fileId}.md\n│   ├── gmail/{threadId}.txt\n│   └── attachments/\n└── temp/  (auto-cleanup on startup)\n\n## Functions\n\nworkspace/manager.py:\n- get_account_folder(account) -> Path\n- get_file_path(account, source, id, ext) -> Path\n- write_content(path, content) -> Path\n- cleanup_temp()\n- init() — called on server start\n\n## Acceptance Criteria\n\n- [ ] Creates folder structure on first use\n- [ ] Returns paths (never content)\n- [ ] Cleans temp/ on startup\n- [ ] Handles multiple accounts (future-proof)", "done": "When complete"}, "created_at": "2026-01-23T07:24:52.622867Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-6fk", "title": "Gmail search format=full may be too heavy", "type": "action", "status": "done", "brief": {"why": "Changed Gmail search from format=metadata to format=full to get attachment names. This fetches entire message bodies just to extract attachment metadata. For threads with large attachments, this bloats memory. Consider: format=metadata + separate attachment query, or accept the tradeoff.", "what": "## Options\n1. Keep format=full — simpler, but heavier payloads\n2. Use format=metadata, then batch-fetch just the parts with attachments\n3. Accept the tradeoff and document it\n\n## Measurement needed\n- Search latency before/after change\n- Memory usage for 20 results with large attachments", "done": "When complete"}, "created_at": "2026-01-25T19:18:08.993636Z", "created_by": "spm1001", "order": 1, "parent": "mise-4mj", "waiting_for": null, "done_at": "2026-02-08T18:28:06Z"}
{"id": "mise-6kh", "title": "Replaced v1 MCP with mise-en-space in production", "type": "outcome", "status": "done", "brief": {"why": "Migrated from beads", "what": "## What Success Looks Like\n\nClaude Code uses mise-en-space instead of mcp-google-workspace. Real workflows work: search → triage → fetch → read. No regressions from v1.\n\n## Acceptance Criteria\n\n- [ ] mise-en-space registered in claude.json\n- [ ] Search deposits to file (token efficient)\n- [ ] Sheets bug fixed (chart sheets filtered)\n- [ ] MCP resources verified in real session\n- [ ] Real workflow tested end-to-end\n\n## Children\n\n- mise-br7: Replace v1 in claude.json (final step)\n- mise-lft: Search deposits to file\n- mise-bpm: Sheets chart sheet bug\n- mise-k80: Test MCP resources\n\n## Why This Matters\n\nUntil v1 is replaced, mise-en-space is a parallel experiment. This epic gates the actual ship.", "done": "When complete"}, "created_at": "2026-01-25T19:48:54.458432Z", "created_by": "spm1001", "order": 2, "done_at": "2026-02-01T10:58:22Z"}
{"id": "mise-6ku", "title": "Claude can search, fetch, AND create across all Workspace content", "type": "outcome", "status": "done", "done_at": "2026-01-25T19:48:43.782962Z", "brief": {"why": "Complete the MCP tool surface. All 3 verbs (search, fetch, create) work across all content types (Drive, Gmail, Contacts).", "what": "## Success Criteria\n\n- [ ] `search(source=\"drive\")` returns file metadata\n- [ ] `search(source=\"gmail\")` returns thread metadata  \n- [ ] `search(source=\"contacts\")` returns people\n- [ ] `fetch(file_id)` works for all supported types\n- [ ] `create(content, type=\"doc\")` creates Google Doc\n- [ ] `create(content, type=\"sheet\")` creates Google Sheet\n- [ ] MCP resources expose capabilities documentation\n\n## Execution Order\n\n1. **mise-3ab** Wire create tool (highest value gap)\n2. **mise-bmk** Implement contacts search (completes search)\n3. **mise-tld** Wire resources (self-documenting)\n\n## Why This Matters\n\nWithout create, Claude can only read. With all 3 verbs, Claude becomes a full Workspace participant — can research, synthesize, AND produce artifacts.", "done": "When complete"}, "created_at": "2026-01-24T20:16:18.445658Z", "created_by": "spm1001", "order": 2}
{"id": "mise-6zd", "title": "Fix silent thumbnail failures in slides adapter", "type": "action", "status": "done", "done_at": "2026-01-25T15:25:55.720724Z", "brief": {"why": "Slides adapter silently swallows all thumbnail fetch exceptions. Missing thumbnails not reported to user.", "what": "## Problem\n\nIn adapters/slides.py `_fetch_thumbnails()`:\n```python\nexcept Exception:\n    pass  # Silent failure - line 112\n```\n\nWhen a thumbnail fails to fetch:\n- No warning added to result\n- No logging\n- User doesn't know slide N is missing\n- Manifest shows has_thumbnails=true even with gaps\n\n## Impact\n\n- Debugging is hard (why is slide 7 missing?)\n- User may think extraction succeeded fully\n- Inconsistent with other extractors (which populate warnings)\n\n## Approach\n\n1. Catch specific exceptions:\n   - HttpError 403: permission denied\n   - HttpError 404: thumbnail not available\n   - Timeout: slow network\n   \n2. Populate warnings for failures:\n   ```python\n   warnings.append(f\"Slide {i}: thumbnail unavailable ({error_type})\")\n   ```\n\n3. Track failed slides in manifest:\n   ```json\n   {\n     \"has_thumbnails\": true,\n     \"thumbnail_failures\": [7, 12]\n   }\n   ```\n\n4. Consider retry for transient failures (already have retry decorator)\n\n## Acceptance Criteria\n\n- [ ] Thumbnail failures logged with reason\n- [ ] warnings list populated for failed slides\n- [ ] Manifest includes thumbnail_failures array\n- [ ] Test with mock that simulates failure\n- [ ] Pass is replaced with explicit handling", "done": "When complete"}, "created_at": "2026-01-24T20:09:32.338581Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-8g5", "title": "Test warning behaviors systematically", "type": "action", "status": "done", "done_at": "2026-01-25T17:36:55.159627Z", "brief": {"why": "Warnings implementation lacks dedicated tests. Need coverage for: empty sheets trigger warning, unknown element types trigger warning, HTML conversion fallback triggers warning, truncation triggers warning. Currently behavior exists but is undertested.", "what": "See title", "done": "When complete"}, "created_at": "2026-01-23T18:07:56.044601Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-8v5", "title": "Find Gemini video summary API endpoint", "type": "action", "status": "done", "done_at": "2026-01-24T11:18:20.078483Z", "brief": {"why": "The Gemini side panel in Drive shows AI summaries of videos — more useful than raw transcript. Need to find the API endpoint that powers this.", "what": "## Context\n\nThe transcript (/timedtext) is raw ASR output. The Gemini summary is processed/distilled — includes:\n- Summary of key points\n- Action items\n- Key topics\n\n## Approach\n\n1. Open video in Drive with Gemini panel visible\n2. Use network intercept to capture requests when panel loads\n3. Look for endpoints containing: gemini, gen_lang, ent-assist, aiplatform\n4. The summary might be streamed (chunked response)\n\n## Why This Matters\n\nFor a sous-chef MCP, the summary is much more valuable than transcript:\n- Token-efficient (distilled, not verbatim)\n- Structured (topics, actions)\n- LLM-ready", "done": "When complete"}, "created_at": "2026-01-24T08:54:00.309936Z", "created_by": "spm1001", "order": 1, "waiting_for": null}
{"id": "mise-9az", "title": "Test infrastructure: sanitized fixtures + adapter mocking", "type": "action", "status": "done", "done_at": "2026-01-23T18:04:14.690475Z", "brief": {"why": "Integration tests use real MIT budget data and hit real APIs. Need: (1) sanitized test fixtures with fake data, (2) mocking infrastructure so adapter unit tests don't need real credentials/APIs.", "what": "## Problem\n\n1. **Real data in fixtures** — test spreadsheet contains actual MIT budget data. If repo goes public or fixtures are shared, data leaks.\n\n2. **No mocking** — adapter tests hit real APIs. Slow, quota-consuming, fragile (test spreadsheet could be deleted).\n\n## Approach\n\n### Sanitized Fixtures\n- Create fake spreadsheet data that exercises same edge cases (multi-tab, special chars, empty cells)\n- Store as JSON in fixtures/sheets/\n- Consider: should integration tests use fixtures or real API? Maybe both (unit uses fixtures, integration uses real)\n\n### Adapter Mocking\n- Mock the Google API service objects\n- Adapters receive mock service, return canned responses\n- Unit tests: fast, no credentials needed\n- Integration tests: real API, needs credentials\n\n## Questions to Resolve\n- Where do mocks live? `tests/mocks/`?\n- Do we use pytest fixtures or a mocking library (unittest.mock, responses)?\n- Should adapters accept service as parameter (dependency injection) for easier mocking?\n\n## Acceptance Criteria\n- [ ] No real company data in committed fixtures\n- [ ] Adapter unit tests run without credentials\n- [ ] Integration tests still work with real API\n- [ ] Clear separation: unit (mocked) vs integration (real)", "done": "When complete"}, "created_at": "2026-01-23T12:27:46.778517Z", "created_by": "spm1001", "order": 1, "waiting_for": null}
{"id": "mise-9jl", "title": "Deposit folder cleanup strategy", "type": "action", "status": "open", "brief": {"why": "mise-fetch/ folders accumulate over time with no cleanup. Need TTL-based or manual cleanup.", "what": "## Problem\n\nEvery fetch creates a folder in mise-fetch/:\n```\nmise-fetch/\n├── slides--deck-1--abc123/\n├── doc--notes--def456/\n├── ...hundreds more over time\n```\n\nNo cleanup = unbounded growth.\n\n## Options\n\n### Option A: TTL-based auto-cleanup\n```python\ndef cleanup_old_deposits(max_age_days: int = 7):\n    \"\"\"Delete deposits older than N days.\"\"\"\n```\n\nPros: Automatic, no user action\nCons: May delete something user wants\n\n### Option B: Manual cleanup command\n```bash\n# MCP tool\nmise cleanup --older-than 7d\n\n# Or expose in manifest\n\"cleanup_hint\": \"safe to delete after 2026-01-31\"\n```\n\nPros: User controls\nCons: Requires user action\n\n### Option C: Versioned deposits\n```\nmise-fetch/\n├── slides--deck-1--abc123--20260124T1200/\n├── slides--deck-1--abc123--20260125T0900/\n```\n\nPros: History preserved\nCons: Even more growth\n\n## Recommendation\n\nStart with Option B (manual) + manifest hint:\n1. Add `cleanup_after` timestamp to manifest.json\n2. Document cleanup approach\n3. Consider auto-cleanup later based on usage\n\n## Acceptance Criteria\n\n- [ ] manifest.json includes cleanup_after field\n- [ ] workspace/manager.py has cleanup function\n- [ ] Documentation explains cleanup\n- [ ] Test cleanup with mock deposits", "done": "When complete"}, "created_at": "2026-01-24T20:10:12.905212Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-9t8", "title": "Fix streaming fallback memory issue for large PDFs", "type": "action", "status": "done", "done_at": "2026-01-25T17:54:39.602587Z", "brief": {"why": "Large PDF Drive conversion still loads entire file into memory after streaming download. A 500MB PDF streams to disk, then OOMs during conversion.", "what": "## Problem\n\n`_fetch_and_extract_pdf_large()` in adapters/pdf.py:\n1. Streams download to temp file (good)\n2. Tries markitdown from disk (good)\n3. If markitdown fails, reads entire file into memory for Drive conversion (bad)\n\n```python\npdf_bytes = tmp_path.read_bytes()  # <-- defeats streaming purpose\nconversion_result = convert_via_drive(file_bytes=pdf_bytes, ...)\n```\n\n## Approach\n\nOption 1: Stream temp file directly to Drive upload\n- `MediaFileUpload` instead of `MediaInMemoryUpload`\n- Requires refactoring conversion.py\n\nOption 2: For large files, skip Drive fallback entirely\n- Document limitation: \"PDFs >X MB use markitdown only\"\n- Simple but reduces extraction quality\n\n## Acceptance Criteria\n- [ ] 500MB PDF doesn't OOM during Drive fallback\n- [ ] Or: Large PDF fallback is gracefully disabled with warning", "done": "When complete"}, "created_at": "2026-01-25T17:28:38.500682Z", "created_by": "spm1001", "order": 1, "waiting_for": null}
{"id": "mise-Bivulu", "type": "outcome", "title": "Create purpose-built test doc with rich comments", "brief": {"why": "Current test_doc_with_comments_id reuses test_doc_id — works but lacks dedicated edge cases", "what": "Create Google Doc in test folder with: threaded replies, resolved/unresolved mix, @mentions, long anchor quotes, empty anchors (like DOCX)", "done": "Fixture exists with predictable comment patterns for regression testing"}, "status": "done", "order": 17, "created_at": "2026-01-31T18:30:00Z", "created_by": "spm1001", "done_at": "2026-02-01T10:58:31Z"}
{"id": "mise-BoVuMo", "type": "action", "title": "Investigate wrong project folder paths in test Claudes", "brief": {"why": "Test Claudes (skill-forge subagent tests) reportedly use wrong project folder paths — deposits may land in unexpected locations. Unclear if it's base_path, MCP cwd scoping, or test harness setup.", "what": "1. Reproduce wrong-path issue in a skill-forge test run 2. Identify root cause (base_path, cwd, MCP scoping) 3. Fix or document the correct pattern", "done": "Test Claudes deposit to the expected location, root cause documented"}, "status": "open", "parent": null, "order": 3, "created_at": "2026-01-31T22:07:47Z", "created_by": "spm1001", "waiting_for": null}
{"id": "mise-DiCewi", "type": "outcome", "title": "Test and exercise new API services", "brief": {"why": "Activity, Tasks, Calendar, Labels APIs added but not yet used in tool layer", "what": "Build search_activity tool using Activity API, test Tasks/Calendar integration, explore Labels for organizational metadata", "done": "At least one new tool using the expanded services, with integration test"}, "status": "done", "order": 18, "created_at": "2026-01-31T18:30:07Z", "created_by": "spm1001", "done_at": "2026-02-01T10:58:31Z"}
{"id": "mise-DiZaje", "type": "action", "title": "Activity fixture capture", "brief": {"why": "Activity adapter unit tests only cover models, not parsing logic. Need fixtures/activity/ with real API responses to test _parse_actor, _parse_target, _parse_comment_action.", "what": "Add capture_activity_fixtures() to scripts/capture_fixtures.py. Capture sample comment activities and file activities. Sanitize email addresses.", "done": "fixtures/activity/comment_activities.json and file_activities.json exist with realistic test data"}, "status": "done", "parent": "mise-3uu", "order": 6, "created_at": "2026-02-01T10:59:20Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Read existing capture script and activity adapter to understand API shape", "Add capture_activity_fixtures() to capture_fixtures.py", "Capture real activity data and sanitize", "Verify fixtures load and are realistic"], "current": 4}, "done_at": "2026-02-09T10:04:02Z"}
{"id": "mise-FutuHe", "type": "action", "title": "Distill bakeoff findings into README", "brief": {"why": "Bakeoff comparison docs (Official vs Organic MCP) are sitting in Test Fixtures. Public repo needs a compelling README showing what mise-en-space does and why.", "what": "Read the 4 bakeoff gdocs, synthesize key findings, write README.md for the public repo", "done": "README.md exists with architecture summary, usage examples, and bakeoff learnings"}, "status": "done", "order": 3, "created_at": "2026-02-01T09:41:55Z", "created_by": "spm1001", "parent": "mise-naviho", "waiting_for": null, "tactical": {"steps": ["Read bakeoff docs", "Draft README", "Review and tighten"], "current": 3}, "done_at": "2026-02-07T21:17:04Z"}
{"id": "mise-GenoSi", "type": "outcome", "title": "Activity API integration tests", "brief": {"why": "Activity adapter has no real API tests — only model unit tests. Need to verify retry wiring, pagination behavior, and error handling against real API.", "what": "Create tests/integration/test_activity.py with tests for search_comment_activities and get_file_activities. Use real credentials, mark with @pytest.mark.integration.", "done": "Integration tests exist, can run with uv run pytest -m integration"}, "status": "done", "order": 15, "created_at": "2026-01-31T17:58:13Z", "created_by": "spm1001", "done_at": "2026-02-01T10:58:31Z"}
{"id": "mise-HoWeKe", "type": "action", "title": "Test and exercise new API services", "brief": {"why": "Activity, Tasks, Calendar, Labels APIs added but not yet used in tool layer", "what": "Build search_activity tool using Activity API, test Tasks/Calendar integration, explore Labels for organizational metadata", "done": "At least one new tool using the expanded services, with integration test"}, "status": "open", "parent": "mise-jy3", "order": 12, "created_at": "2026-02-01T10:59:22Z", "created_by": "spm1001", "waiting_for": null}
{"id": "mise-Katuwe", "type": "action", "title": "Add mise-fetch cleanup mechanism", "brief": {"why": "Deposited files in mise-fetch/ accumulate indefinitely. No automatic cleanup.", "what": "Per-directory TTL cleanup. With base_path, deposits scatter across project directories — each mise-fetch/ is self-contained, so cleanup is local not centralised. Options: (1) TTL flag on fetch (--cleanup-older-than 7d) (2) standalone 'do(operation=cleanup)' via the do verb (3) external cron (find ~/Repos/*/mise-fetch -mtime +7). Workspace manager already has list_deposit_folders() + parse_folder_name() infrastructure.", "done": "Cleanup mechanism implemented and tested"}, "status": "done", "parent": "mise-jy3", "order": 7, "created_at": "2026-02-01T10:59:44Z", "created_by": "spm1001", "waiting_for": null, "done_at": "2026-02-09T23:15:31Z"}
{"id": "mise-KewiCi", "type": "outcome", "title": "Phase 2: Cookie authentication for web fetch", "brief": {"why": "Authenticated sites (docs behind login, corporate wikis) need cookie injection. CDP adapter already exists for video summaries.", "what": "Integrate CDP cookie exfiltration with web adapter. Add cookie forwarding when auth required. Test with authenticated site.", "done": "fetch() works on auth-required pages when chrome-debug running"}, "status": "done", "order": 24, "created_at": "2026-02-01T15:23:07Z", "created_by": "spm1001", "done_at": "2026-02-06T20:11:52Z"}
{"id": "mise-Lovobo", "type": "outcome", "title": "Integration test for Gmail attachment extraction", "brief": {"why": "Current tests are unit-level; need to verify download → extract → deposit flow with real thread", "what": "Create test fixture with PDF attachment, write integration test that fetches thread and verifies PDF content is deposited", "done": "Integration test passes with real Gmail API call"}, "status": "done", "order": 9, "created_at": "2026-01-29T23:25:53Z", "created_by": "spm1001", "done_at": "2026-02-01T10:58:29Z"}
{"id": "mise-NiKuki", "type": "action", "title": "Surface action items from Workspace APIs", "brief": {"why": "Action items scattered across 3 sources: (1) Tasks API, (2) Activity API (comments mentioning you), (3) Assigned tasks in Docs — buried with no central view.", "what": "1. Explore all 3 sources for action item surfacing 2. Tasks API → sync to todoist-gtd or just surface? 3. Activity API → filter for mentions, extract action items 4. Docs assigned tasks → can we find these? 5. Decide: sous-chef surfaces, pipes to todoist-gtd, or both", "done": "Clear decision on each source: ignore, surface via fetch enrichment, or pipe to todoist-gtd"}, "status": "open", "parent": "mise-jy3", "order": 6, "created_at": "2026-02-01T10:59:43Z", "created_by": "spm1001", "waiting_for": null}
{"id": "mise-PepuZa", "type": "outcome", "title": "Wire pre-exfil lookup in fetch_gmail", "brief": {"why": "Pre-exfil optimization skips Gmail download for already-indexed files", "what": "Call lookup_exfiltrated() in fetch_gmail before downloading attachments. If file exists in Drive with Message ID match, fetch from Drive instead of Gmail.", "done": "fetch_gmail checks pre-exfil folder, uses Drive file when available"}, "status": "done", "order": 8, "created_at": "2026-01-29T23:25:48Z", "created_by": "spm1001", "done_at": "2026-02-01T10:58:29Z"}
{"id": "mise-Recebe", "type": "action", "title": "Parameterize Apps Script year functions", "brief": {"why": "backfillDriveLinks2023/2024/2025 are copy-paste boilerplate. Adding 2026 required code edits. Should be config-driven like attachment backfill.", "what": "1. Add years to BACKFILL_YEARS config array 2. Single backfillDriveLinksForYear(year) function 3. Remove year-specific boilerplate 4. Update any triggers", "done": "Adding a new year is config change only, no code duplication"}, "status": "open", "parent": "mise-tagemu", "order": 2, "created_at": "2026-01-29T22:34:56Z", "created_by": "spm1001", "waiting_for": null}
{"id": "mise-Sadulo", "type": "outcome", "title": "Calendar context in search results", "brief": {"why": "Docs don't exist in isolation. Meeting context explains why a doc matters — who was in the meeting, when it happened, what other docs were linked.", "what": "1. Add source='calendar' option to search, or enrich Drive results with calendar context\n2. Query calendar.events() for recent events with attachments\n3. Cross-reference file IDs with search results\n4. Add meeting context to result metadata: 'This doc was attached to Q4 Planning meeting on Jan 15'", "done": "Search results include meeting context when available"}, "status": "done", "order": 14, "created_at": "2026-01-31T17:49:13Z", "created_by": "spm1001", "done_at": "2026-02-01T10:58:33Z"}
{"id": "mise-Sojuci", "type": "outcome", "title": "Add mise-fetch cleanup mechanism", "brief": {"why": "Deposited files in mise-fetch/ accumulate indefinitely. No automatic cleanup.", "what": "Options: (1) age-based cleanup in workspace/manager.py (2) max folder count (3) manual cleanup skill/command", "done": "Cleanup mechanism implemented and tested"}, "status": "done", "order": 21, "created_at": "2026-01-31T20:49:46Z", "created_by": "spm1001", "done_at": "2026-02-01T10:58:33Z"}
{"id": "mise-Tojoni", "type": "action", "title": "Probe: does mise need a coupled skill?", "brief": {"why": "v1 had a detailed skill; v2 is simpler. Test MCP-only for a week and note friction points.", "what": "Evidence gathered from mem (15+ sessions), field reports, handoffs, and 4 exemplar skill+tool pairings. Findings: (1) Test Claudes skip skill and make mistakes — keyword soup, miss comments, forget base_path. (2) MANDATORY gate (CSO 80) needed for skill to load. (3) Skill value concentrates in research mode (exploration loop), low for simple fetch. (4) Design: MANDATORY, ~150 line SKILL.md coaching research workflow, references/ for mechanical detail. Decision: yes, mise needs coupled skill.", "done": "Decision made: no skill needed / create minimal skill / port v1 skill"}, "status": "done", "parent": "mise-tuguzi", "order": 2, "created_at": "2026-02-01T10:59:54Z", "created_by": "spm1001", "waiting_for": null, "done_at": "2026-02-09T15:16:58Z"}
{"id": "mise-Vujali", "type": "action", "title": "Deprecate google-workspace skill", "brief": {"why": "Two Workspace skills exist: google-workspace (v1 MCP) and mise (v2 MCP). This causes confusion about which to use.", "what": "1. Add deprecation notice to google-workspace SKILL.md pointing to mise 2. Update filing skill references 3. Consider removing after transition period", "done": "google-workspace skill marked deprecated; references updated to mise"}, "status": "done", "parent": "mise-tuguzi", "order": 1, "created_at": "2026-01-31T22:07:29Z", "created_by": "spm1001", "waiting_for": null, "done_at": "2026-02-09T15:17:26Z"}
{"id": "mise-Zoluca", "type": "outcome", "title": "Probe: does mise need a coupled skill?", "brief": {"why": "v1 had a detailed skill; v2 is simpler. Test MCP-only for a week and note friction points.", "what": "Use mise tools directly for a week. Track: (1) What patterns repeat? (2) What context is missing? (3) Would a skill help?", "done": "Decision made: no skill needed / create minimal skill / port v1 skill"}, "status": "done", "order": 20, "created_at": "2026-01-31T20:49:39Z", "created_by": "spm1001", "done_at": "2026-02-01T10:58:34Z"}
{"id": "mise-baJije", "type": "action", "title": "Replace v1 in claude.json", "brief": {"why": "Final step to ship mise-en-space. v1 still registered, this swaps it.", "what": "1. Update ~/.claude.json mcpServers 2. Point to mise-en-space server.py 3. Test real Claude session 4. Keep v1 commented for rollback", "done": "mise-en-space registered, Claude can call search/fetch/create, real workflow tested"}, "status": "done", "parent": "mise-6kh", "order": 1, "created_at": "2026-01-29T22:14:17Z", "created_by": "spm1001", "waiting_for": null, "done_at": "2026-01-31T20:50:04Z"}
{"id": "mise-bituzo", "type": "action", "title": "Real email signature stripping gap", "brief": {"why": "Real ITV email signatures (name/title/org/links block) aren't caught by talon stripper. Discovered when testing with real_thread.json fixture — quoted original is stripped but multi-line corporate signature passes through.", "what": "1. Analyze real signature patterns from fixture 2. Evaluate talon_signature.py rules 3. Add pattern for multi-line corporate sigs or accept as known limitation", "done": "Either signature is stripped from real fixture reply, or documented as accepted limitation with test"}, "status": "done", "parent": "mise-3uu", "order": 19, "created_at": "2026-02-09T09:53:55Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Check real fixture signature pattern", "Add test documenting limitation", "Close as accepted limitation"], "current": 3}, "done_at": "2026-02-09T11:44:06Z"}
{"id": "mise-bl9", "title": "Round-trip extractor tests with real fixtures", "type": "action", "status": "done", "done_at": "2026-01-25T17:35:34.483094Z", "brief": {"why": "Test that extractors produce expected content from real API fixtures, not just 'does it crash' smoke tests. Should verify known content appears in output.", "what": "## Approach\n\nFor each real fixture, add tests that check specific expected content:\n- real_multi_tab.json → verify tab titles, some known text appears\n- real_spreadsheet.json → verify cell values round-trip\n- real_gmail.json → verify message bodies extracted, signatures stripped\n\nThis catches regressions where extractor 'works' but produces wrong output.", "done": "When complete"}, "created_at": "2026-01-23T15:48:54.268436Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-bmk", "title": "Implement contacts search", "type": "action", "status": "done", "done_at": "2026-01-25T16:57:22.882997Z", "brief": {"why": "Search tool returns 'Contacts search not yet implemented' for source='contacts'. Complete the search surface.", "what": "## Current State\n\nIn tools/search.py:79-80:\n```python\nelif source == \"contacts\":\n    return {\"error\": True, \"message\": \"Contacts search not yet implemented\"}\n```\n\nPeople API utilities exist in v1 (mcp-google-workspace) but not wired here.\n\n## Scope\n\n1. Add contacts adapter\n2. Define ContactResult model\n3. Wire to search tool\n4. Test with real contacts\n\n## Approach\n\n### 1. Model (models.py)\n\n```python\n@dataclass\nclass ContactResult:\n    resource_name: str  # people/c123...\n    display_name: str\n    email_addresses: list[str]\n    phone_numbers: list[str]\n    organization: str | None\n    job_title: str | None\n    source: Literal[\"directory\", \"contacts\"]\n```\n\n### 2. Adapter (adapters/contacts.py)\n\n```python\ndef search_contacts(query: str, max_results: int = 10) -> list[ContactResult]:\n    \"\"\"\n    Search BOTH organization directory AND personal contacts.\n    \n    - Directory: searchDirectoryPeople (requires directory.readonly)\n    - Contacts: searchContacts (requires contacts.readonly)\n    \"\"\"\n```\n\nPort from v1's lookup_contact() which already handles both sources.\n\n### 3. Wire to search.py\n\n```python\nelif source == \"contacts\":\n    results = search_contacts(query, max_results)\n    return [r.to_dict() for r in results]\n```\n\n## Acceptance Criteria\n\n- [ ] ContactResult model defined\n- [ ] adapters/contacts.py with search function\n- [ ] search(source=\"contacts\") returns results\n- [ ] Searches both directory and personal contacts\n- [ ] Integration test with real contacts", "done": "When complete"}, "created_at": "2026-01-24T20:09:44.378821Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-bpm", "title": "Sheets adapter should filter out non-GRID sheets", "type": "action", "status": "done", "done_at": "2026-01-25T20:13:57.052776Z", "brief": {"why": "fetch_spreadsheet crashes when spreadsheet has chart sheets (sheetType=OBJECT). Should filter to only GRID sheets like capture_fixtures.py does.", "what": "## Original Bug\nsheets.fetch_spreadsheet crashes when spreadsheet has chart sheets (sheetType=OBJECT).\nChart sheets don't have cell ranges → API error \"Invalid range: 'Chart1'\"\n\n## Status (Jan 2026)\n**Absorbed into mise-w6f (chart rendering).**\n\nThe fix is no longer \"filter out chart sheets\" — it's \"render chart sheets as images.\" \nmise-w6f handles both:\n1. Filter GRID sheets for cell values\n2. Render ALL charts (from GRID and OBJECT sheets) as PNGs\n\n## Do not close separately\nThis bead is resolved when mise-w6f is complete.", "done": "When complete"}, "created_at": "2026-01-25T19:14:54.267196Z", "created_by": "spm1001", "order": 1, "parent": "mise-6kh", "waiting_for": null}
{"id": "mise-br7", "title": "Replace v1 in claude.json", "type": "action", "status": "open", "brief": {"why": "Swap mcp-google-workspace for mise-en-space in Claude config. Final ship step.", "what": "## Steps\n\n1. Update ~/.claude.json mcpServers entry\n2. Point to mise-en-space server.py\n3. Test with real Claude session\n4. Verify search + fetch workflow works\n\n## Rollback\n\nKeep v1 config commented, easy to revert if issues.\n\n## Acceptance Criteria\n\n- [ ] mise-en-space registered in claude.json\n- [ ] Claude can call search, fetch, create, help\n- [ ] Real workflow tested (find doc, fetch, read)", "done": "When complete"}, "created_at": "2026-01-23T07:25:54.786555Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-busafe", "type": "action", "title": "Activity API search source", "brief": {"why": "Action items discovery needs efficient cross-file search. Activity API can find all comment events in one call vs N+1 queries through comments endpoint.", "what": "1. Add source='activity' option to search tool 2. Query activity.query(filter='detail.action_detail_case:COMMENT') 3. Filter to mentionedUsers containing current user 4. Return files with open action items", "done": "search(source='activity') returns files with action items for current user"}, "status": "open", "parent": "mise-jy3", "order": 4, "created_at": "2026-02-01T10:59:40Z", "created_by": "spm1001", "waiting_for": null}
{"id": "mise-bx8", "title": "Escape search query input", "type": "action", "status": "done", "done_at": "2026-01-24T21:55:52.70237Z", "brief": {"why": "Search queries passed directly to Drive/Gmail APIs without escaping. Security risk and correctness issue.", "what": "## Problem\n\nIn tools/search.py:\n```python\nquery = f\"fullText contains '{query}'\"  # line 61\n```\n\nUser input with quotes breaks the query or could inject malicious Drive query operators.\n\n## Scope\n\n1. Drive search - fullText contains clause\n2. Gmail search - query passed directly\n3. Contacts search (when implemented)\n\n## Approach\n\n1. Create `validation.py:escape_drive_query(query: str) -> str`\n   - Escape single quotes: `'` → `\\'`\n   - Escape backslashes: `\\` → `\\\\`\n   \n2. Create `validation.py:validate_gmail_query(query: str) -> str`\n   - Validate against known Gmail operators\n   - Reject/escape dangerous patterns\n   \n3. Update search.py to use these functions\n\n4. Add tests with malicious inputs:\n   - Quotes: `test' OR name contains 'secret`\n   - Operators: `mimeType:application/pdf`\n   - Unicode edge cases\n\n## Acceptance Criteria\n\n- [ ] Drive queries with quotes don't break\n- [ ] Gmail queries with special chars handled\n- [ ] Tests cover injection attempts\n- [ ] No user input reaches API unescaped", "done": "When complete"}, "created_at": "2026-01-24T20:08:51.56354Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-cecuzu", "type": "action", "title": "Gmail search results arrive in relevance order", "brief": {"why": "Gmail batch callbacks (adapters/gmail.py search_threads, lines 245-301) return results in server callback order, not the relevance order from threads().list(). Titans review Epimetheus #13 (Feb 2026). Low user impact currently but technically wrong — search results should be deterministic and relevance-sorted.", "what": "1. In search_threads, capture original thread order from threads().list() response 2. Index batch callback results by thread_id 3. Reorder final results list to match original relevance ranking 4. Add test confirming ordering is preserved", "done": "Gmail search results returned in same order as threads().list() response, with test"}, "status": "done", "parent": "mise-jy3", "order": 18, "created_at": "2026-02-09T21:21:08Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["In search_threads, capture original thread order from threads().list() response", "Index batch callback results by thread_id", "Reorder final results list to match original relevance ranking", "Add test confirming ordering is preserved"], "current": 4}, "done_at": "2026-02-09T23:09:45Z"}
{"id": "mise-cedije", "type": "action", "title": "Truncation guard for inline attachment text", "brief": {"why": "No longer needed — inline embedding was removed entirely (a0a7a45), so there is nothing to truncate. The separate .pdf.md file is the single source for extracted attachment text.", "what": "1. Add max_inline_chars parameter to the embedding loop in fetch_gmail (default ~10000 chars) 2. When exceeded, truncate with note pointing to the separate .md file 3. Test with synthetic large content", "done": "content.md stays readable even with large/malformed PDF attachments. Full text available in separate file."}, "status": "done", "parent": "mise-4mj", "order": 9, "created_at": "2026-02-08T19:50:57Z", "created_by": "spm1001", "waiting_for": null, "done_at": "2026-02-08T21:12:21Z"}
{"id": "mise-cejepo", "type": "action", "title": "Forced-browser deposits get real titles from pre_extracted_content H1", "brief": {"why": "When use_browser=True, html='' so extract_title returns nothing. Folder names are always web--web-page--hash. The markdown from passe typically starts with # Title which could be used.", "what": "1. In tools/fetch/web.py, after pre_extracted_content path, extract title from first H1 line 2. Fall back to URL-derived title if no H1 3. Add test for H1 extraction", "done": "Forced-browser deposits have real titles in folder names and metadata, not 'web-page'"}, "status": "open", "parent": "mise-jy3", "order": 22, "created_at": "2026-02-13T10:59:50Z", "created_by": "spm1001", "waiting_for": null}
{"id": "mise-cewowe", "type": "action", "title": "Shared fixture loader in conftest.py", "brief": {"why": "Every adapter test file does its own json.loads(Path(...).read_text()). Duplicated, no type coercion, no validation that fixture exists.", "what": "Add load_fixture(category, name) to tests/conftest.py that returns raw dict. Optionally returns typed dataclass via existing conftest converters. Refactor test files to use it.", "done": "All test files using fixtures import from conftest. Missing fixture gives clear error at collection time, not runtime."}, "status": "done", "parent": "mise-3uu", "order": 14, "created_at": "2026-02-09T07:20:23Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Replace inline json.loads in test_docs_adapter.py with load_fixture", "Replace inline json.loads in test_gmail_adapter.py with load_fixture", "Check test_negative_paths.py — separate malformed path, may need a load_malformed_fixture or just leave", "Verify all tests pass"], "current": 4}, "done_at": "2026-02-09T09:42:34Z"}
{"id": "mise-chf", "title": "Port sheets extractor — prove the pattern", "type": "action", "status": "done", "done_at": "2026-01-23T07:34:27.980862Z", "brief": {"why": "Simplest extractor (138 lines). Port to pure function to validate architecture.", "what": "## Why First\n\n- 138 lines, single function\n- Clear input → output\n- If this works, others follow same pattern\n\n## Porting Steps\n\n1. Copy extraction logic from v1 tools/sheets.py\n2. Remove get_sheets_service() call\n3. Change signature: extract_sheets(response: dict) -> str\n4. Add type hints\n5. Write unit test with fixture\n\n## Acceptance Criteria\n\n- [ ] extractors/sheets.py exists with pure function\n- [ ] Unit test with mocked API response passes\n- [ ] No imports from adapters or tools", "done": "When complete"}, "created_at": "2026-01-23T07:24:11.833893Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-cohato", "type": "action", "title": "Parallelize Drive + Gmail search", "brief": {"why": "Search with both sources runs sequentially (~2.3s). Drive and Gmail are independent API calls that could run concurrently, cutting latency roughly in half to ~1s.", "what": "1. Use concurrent.futures.ThreadPoolExecutor (or asyncio.to_thread) to run search_drive_files and search_gmail_threads in parallel 2. Merge results after both complete 3. Benchmark to confirm improvement", "done": "search('query') with both sources completes in ≤1.5s average (down from 2.3s)"}, "status": "done", "parent": "mise-weduje", "order": 1, "created_at": "2026-02-09T06:29:58Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Use concurrent.futures.ThreadPoolExecutor (or asyncio.to_thread) to run search_drive_files and search_gmail_threads in parallel", "Merge results after both complete", "Benchmark to confirm improvement"], "current": 3}, "done_at": "2026-02-09T06:42:01Z"}
{"id": "mise-cunufu", "type": "outcome", "title": "Cross-source search ergonomics", "brief": {"why": "When bouncing between Drive and Gmail to find context, tools don't hint at linkage opportunities", "what": "MCP resource documenting patterns, metadata enrichment for exfil'd files, expose email context", "done": "All acceptance criteria met"}, "status": "done", "order": 2, "created_at": "2026-01-29T21:12:14Z", "created_by": "spm1001", "done_at": "2026-01-29T21:14:57Z"}
{"id": "mise-curuci", "type": "action", "title": "Survey meeting note patterns in Drive", "brief": {"why": "Need to understand variety: Google Meet transcripts vs manual notes vs Fireflies vs Notion imports", "what": "Sample 10-20 meeting notes, document common patterns and section types", "done": "Have categorization of meeting note formats with example snippets"}, "status": "done", "parent": "mise-fetifo", "order": 1, "created_at": "2026-01-30T12:49:21Z", "created_by": "spm1001", "waiting_for": null, "done_at": "2026-01-30T14:04:33Z"}
{"id": "mise-cuviCi", "type": "action", "title": "Add description field to Drive metadata", "brief": {"why": "Enables detection of exfil'd files via Message ID in description", "what": "Add description to FILE_METADATA_FIELDS, surface in results", "done": "Description field accessible in search/fetch results"}, "status": "done", "parent": "mise-cunufu", "order": 2, "created_at": "2026-01-29T21:12:25Z", "created_by": "spm1001", "waiting_for": null, "done_at": "2026-01-29T21:13:22Z"}
{"id": "mise-da6", "title": "Fix sheets adapter to use batchGet", "type": "action", "status": "done", "done_at": "2026-01-23T12:12:01.497189Z", "brief": {"why": "Current sheets adapter makes N+1 API calls (1 metadata + N tabs). Should use values().batchGet() to fetch all tabs in one call.", "what": "## Current (N+1 calls)\n\n```python\nfor sheet_name in sheet_names:\n    values_response = service.spreadsheets().values().get(\n        spreadsheetId=spreadsheet_id,\n        range=f\"'{sheet_name}'\",\n    ).execute()\n```\n\n## Should Be (2 calls)\n\n```python\nranges = [f\"'{name}'\" for name in sheet_names]\nbatch_response = service.spreadsheets().values().batchGet(\n    spreadsheetId=spreadsheet_id,\n    ranges=ranges,\n    valueRenderOption=\"FORMATTED_VALUE\",\n).execute()\n```\n\n## Acceptance Criteria\n\n- [ ] Uses batchGet instead of per-tab get\n- [ ] Integration test still passes\n- [ ] Quota usage reduced (verify with rate limit test)", "done": "When complete"}, "created_at": "2026-01-23T12:11:05.193664Z", "created_by": "spm1001", "order": 1, "waiting_for": null}
{"id": "mise-dezezi", "type": "action", "title": "AGENTS.md for visiting Claudes", "brief": {"why": "Team Claudes working in this repo need to know: don't modify architecture, file issues not PRs, how to run tests, layer rules", "what": "1. Expand existing AGENTS.md with repo conventions and architecture summary 2. Add test commands and quality gates 3. Add issue filing guidance for Claude agents 4. Document pre-ship/post-ship outcome split", "done": "A teammate's Claude can clone, orient, and file a good bug report without breaking conventions"}, "status": "done", "parent": "mise-naviho", "order": 6, "created_at": "2026-02-07T18:50:36Z", "created_by": "spm1001", "waiting_for": null, "done_at": "2026-02-07T22:54:35Z"}
{"id": "mise-dinidi", "type": "action", "title": "httpx mock helper for web adapter tests", "brief": {"why": "test_web.py has ~20 repetitions of the httpx.Client context manager mock pattern (mock_client_cls.return_value.__enter__/exit). This is verbose and non-obvious. A fixture or helper would reduce boilerplate and make tests more readable.", "what": "1. Create a pytest fixture or helper that yields a mock httpx client with the context manager wired up 2. Refactor test_web.py to use the helper 3. Consider respx library as alternative", "done": "No repeated __enter__/__exit__ boilerplate in test_web.py, all tests still pass"}, "status": "done", "parent": "mise-3uu", "order": 16, "created_at": "2026-02-09T08:09:35Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Create a pytest fixture or helper that yields a mock httpx client with the context manager wired up", "Refactor test_web.py to use the helper", "Consider respx library as alternative"], "current": 3}, "done_at": "2026-02-09T08:34:29Z"}
{"id": "mise-dvs", "title": "Fix mypy errors across codebase", "type": "action", "status": "done", "done_at": "2026-01-25T17:11:55.514772Z", "brief": {"why": "Ran mypy on entire codebase, found 44 errors. Fixed critical one (missing Any import). Remaining errors need attention.", "what": "## Error Summary (44 total)\n- tools/fetch.py: 25 errors (type conflicts, missing generics)\n- server.py: 6 errors (Optional types, missing generics)\n- adapters/: 8 errors (Literal mismatches, missing generics)\n- extractors/: 1 error (Any return)\n\n## Key Issues\n1. **Return type mismatches** — Functions return FetchResult but typed as dict\n2. **Missing Optional** — `sources: list[str] = None` needs `| None`\n3. **Missing generics** — `dict` instead of `dict[str, Any]`\n4. **Literal mismatches** — string vs Literal type conflicts\n\n## Quick Fixes Done\n- Added `Any` import to tools/create.py\n\n## Acceptance Criteria\n- [ ] `uv run mypy` passes with 0 errors\n- [ ] Types are accurate, not just silenced", "done": "When complete"}, "created_at": "2026-01-25T17:00:03.005754Z", "created_by": "spm1001", "order": 1, "waiting_for": null}
{"id": "mise-dyd", "title": "mise-en-space handles edge cases and errors gracefully", "type": "outcome", "status": "done", "done_at": "2026-01-25T19:48:44.598541Z", "brief": {"why": "Robustness and security. No silent failures, no injection vectors, warnings surfaced to user.", "what": "## Success Criteria\n\n- [ ] Search queries with quotes/special chars don't break or inject\n- [ ] Thumbnail fetch failures reported (not silently swallowed)\n- [ ] Table rowSpan handled correctly\n- [ ] Temp files cleaned up (or cleanup documented)\n- [ ] All warnings flow through to manifest.json\n\n## Execution Order\n\n1. **mise-bx8** Escape search query input (security - do first)\n2. **mise-2h2** Handle rowSpan in table parsing (correctness)\n3. **mise-6zd** Fix silent thumbnail failures (observability)\n4. **mise-mii** Handle orphaned temp files (cleanup)\n\n## Why This Matters\n\nSilent failures erode trust. Claude thinks extraction succeeded when it didn't. Security issues (query injection) could expose data. Robustness = reliability.", "done": "When complete"}, "created_at": "2026-01-24T20:16:26.882981Z", "created_by": "spm1001", "order": 2}
{"id": "mise-e0e", "title": "Wire search tool", "type": "action", "status": "done", "done_at": "2026-01-23T22:13:09.483681Z", "brief": {"why": "Unified search across Drive + Gmail. Returns metadata only, no files written.", "what": "## Signature\n\nsearch(query: str, sources: list[str] = ['drive', 'gmail'], max_results: int = 20) -> dict\n\n## Response Shape\n\n{\n  \"drive_results\": [\n    {\"id\": \"...\", \"name\": \"...\", \"mimeType\": \"...\", \"modified\": \"...\", \"url\": \"...\"}\n  ],\n  \"gmail_results\": [\n    {\"thread_id\": \"...\", \"subject\": \"...\", \"snippet\": \"...\", \"date\": \"...\", \"from\": \"...\"}\n  ]\n}\n\n## Key Behaviors\n\n- Separate lists per source (not merged)\n- Drive: fullText match IS the triage (no snippets needed)\n- Gmail: snippet from API\n- Includes exfiltrated attachments (they're in Drive)\n- Contacts deferred for now\n\n## URL Handling\n\nAccept Gmail URLs, convert to thread ID:\nhttps://mail.google.com/mail/u/0/#inbox/18f4a... → thread_id\n\n## Acceptance Criteria\n\n- [ ] Searches Drive and Gmail in parallel\n- [ ] Returns separate result lists\n- [ ] Handles Gmail URLs\n- [ ] max_results works per source", "done": "When complete"}, "created_at": "2026-01-23T07:25:02.686984Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-e5o", "title": "Create pre-exfil test fixture", "type": "action", "status": "open", "brief": {"why": "Email with attachment that's been exfiltrated to Drive. Needed to test pre-exfil detection.", "what": "## What's Needed\n\n1. Find an email with attachment in user's Gmail\n2. Verify the attachment exists in \"Email Attachments\" folder\n3. Note: email thread ID, attachment filename, Drive file ID\n4. Add to EXPERIMENTS.md fixtures table\n\n## Test Case\n\nfetch(attachment_id) should:\n1. Detect pre-exfiltrated version exists\n2. Fetch from Drive (not Gmail)\n3. Return path to Drive-sourced file", "done": "When complete"}, "created_at": "2026-01-23T07:30:06.326602Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-eqi", "title": "Add negative path tests", "type": "action", "status": "done", "done_at": "2026-01-25T17:23:35.075557Z", "brief": {"why": "No tests for malformed input, missing fields, or error conditions. Extractors need resilience testing.", "what": "## Problem\n\nCurrent tests only cover happy paths:\n- Valid fixtures → expected output\n- No tests for: null fields, missing objectId, empty content, malformed structures\n\n## Gap Analysis\n\n### Extractors\n\n| Extractor | Missing Tests |\n|-----------|---------------|\n| docs.py | Missing inlineObject reference, null textRun content |\n| sheets.py | Empty spreadsheet, null cell values, malformed rows |\n| slides.py | Missing objectId, null shape content, empty tables |\n| gmail.py | Decode errors, missing body parts, malformed MIME |\n\n### Adapters\n\n| Adapter | Missing Tests |\n|---------|---------------|\n| All | 429 rate limit response |\n| All | 5xx server error |\n| All | Network timeout |\n| All | Invalid credentials (401) |\n\n### Validation\n\n| Function | Missing Tests |\n|----------|---------------|\n| extract_drive_file_id | Malformed URLs, empty string |\n| extract_gmail_id | Invalid web IDs, empty string |\n| convert_gmail_web_id | Edge case IDs |\n\n## Approach\n\n1. Create fixtures/malformed/ directory with bad inputs\n2. Test each extractor with malformed data\n3. Verify graceful degradation (warnings, not crashes)\n4. Test adapters with mocked error responses (see mise-h6m)\n\n## Acceptance Criteria\n\n- [ ] fixtures/malformed/ contains edge case fixtures\n- [ ] Each extractor has negative path tests\n- [ ] Extractors produce warnings not exceptions for recoverable errors\n- [ ] Tests document expected behavior for each error type", "done": "When complete"}, "created_at": "2026-01-24T20:10:39.234734Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-fetifo", "type": "outcome", "title": "Meeting notes are distilled to high-signal summaries", "brief": {"why": "Meeting notes are context busters with high chaff — raw extraction wastes tokens and buries decisions", "what": "Extraction strategy that reduces meeting notes to structured signal: decisions, action items, key points", "done": "Can fetch a meeting note and get ~500 words of structured signal instead of 5000 words of raw content"}, "status": "done", "order": 12, "created_at": "2026-01-30T12:49:16Z", "created_by": "spm1001", "done_at": "2026-01-31T16:33:07Z"}
{"id": "mise-fiWiBe", "type": "outcome", "title": "Embed extracted PDF content in content.md", "brief": {"why": "Currently PDFs are deposited separately; Claude must Read them explicitly. Should embed text like Drive PDFs.", "what": "After extracting PDF attachment, append extracted markdown to thread content.md (like we do for Drive PDFs). Keep raw PDF file for reference.", "done": "content.md includes inline PDF text for all extracted attachments"}, "status": "done", "order": 11, "created_at": "2026-01-29T23:26:05Z", "created_by": "spm1001", "done_at": "2026-02-01T10:58:29Z"}
{"id": "mise-fuSepi", "type": "action", "title": "Fix cwd bug — deposits go to MCP dir not Claude's cwd", "brief": {"why": "MCP servers run as separate processes. Path.cwd() returns MCP's directory, not Claude's working directory. All deposits accumulate in mise-en-space/mise-fetch/ regardless of where Claude is working.", "what": "1. Add base_path parameter to search() and fetch() tools 2. Pass through to workspace manager 3. Default to cwd for backwards compat 4. Document in skill", "done": "Deposits appear in Claude's working directory when base_path passed; mise skill updated"}, "status": "done", "parent": "mise-naviho", "order": 1, "created_at": "2026-01-31T22:07:22Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Add base_path parameter to search() and fetch() tools", "Pass through to workspace manager", "Default to cwd for backwards compat", "Document in skill"], "current": 4}, "done_at": "2026-02-07T20:58:44Z"}
{"id": "mise-fulawu", "type": "outcome", "title": "Phase 3: Full webctl browser integration", "brief": {"why": "JS-rendered pages (SPAs, Next.js) need browser rendering. webctl fallback exists but is untested.", "what": "Test browser fallback with real JS-heavy pages. Verify cookie forwarding works. Add integration tests.", "done": "fetch() extracts content from React/Next.js sites when webctl running"}, "status": "done", "order": 25, "created_at": "2026-02-01T15:23:19Z", "created_by": "spm1001", "done_at": "2026-02-06T20:11:52Z"}
{"id": "mise-g9i", "title": "Wire adapters — Google API wrappers", "type": "action", "status": "done", "done_at": "2026-01-23T18:32:00.02925Z", "brief": {"why": "Thin wrappers that call Google APIs and pass responses to extractors. Thread-safe.", "what": "## Pattern\n\nFrom V2.md research:\n- Use requestBuilder pattern for thread safety\n- Always use fields parameter for partial responses\n- **BATCH API CALLS** — whenever making multiple calls of the same type, batch them\n\n## Batching Requirements (MANDATORY)\n\n| Adapter | What to batch | How |\n|---------|---------------|-----|\n| sheets | Multiple tabs | `values().batchGet(ranges=[...])` |\n| gmail | Multiple messages in thread | `new_batch_http_request()` |\n| slides | Selected thumbnail fetches | `new_batch_http_request()` |\n| drive | Multiple file metadata | `new_batch_http_request()` |\n| docs | Inline image fetches | `new_batch_http_request()` if multiple |\n\n## Adapters Needed\n\nadapters/drive.py:\n- get_file_metadata(file_id)\n- export_file(file_id, mime_type) \n- search_files(query, max_results)\n\nadapters/gmail.py:\n- get_thread(thread_id) — batch fetches all messages\n- get_message(message_id)\n- search_threads(query, max_results)\n\nadapters/docs.py:\n- get_document(doc_id)\n\nadapters/sheets.py:\n- get_spreadsheet(spreadsheet_id) — uses batchGet for tabs\n\nadapters/slides.py:\n- get_presentation(presentation_id)\n- get_thumbnails(presentation_id, slide_ids) — batched\n\n## Acceptance Criteria\n\n- [ ] All adapters use fields parameter\n- [ ] All adapters use batch APIs where applicable (see table above)\n- [ ] Gmail uses batch endpoint internally\n- [ ] Sheets uses batchGet for multiple tabs\n- [ ] Thread-safe (requestBuilder pattern)\n- [ ] Integration test with real API passes", "done": "When complete"}, "created_at": "2026-01-23T07:24:44.671222Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-g9i.1", "title": "Write sheets adapter", "type": "action", "status": "done", "done_at": "2026-01-23T11:35:00.401404Z", "brief": {"why": "First real adapter. Calls Sheets API, assembles SpreadsheetData, proves end-to-end pattern. Use @with_retry decorator. Follow search_/fetch_/create_ naming.", "what": "See title", "done": "When complete"}, "created_at": "2026-01-23T09:03:40.499314Z", "created_by": "spm1001", "order": 1, "parent": "mise-g9i", "waiting_for": null}
{"id": "mise-gajori", "type": "action", "title": "Forage: native CDP browser fallback replacing webctl", "brief": {"why": "mise's web fetch needs browser rendering for JS-heavy and auth'd pages. Currently shells out to webctl (Playwright daemon, heavy deps). Chrome Debug on port 9222 already runs with user's Google SSO. mise already has websockets dep. A thin CDP adapter gives mise direct browser access — zero new deps, inherits auth, and chrome-log captures traffic as a free side effect.", "what": "1. Create adapters/cdp.py — thin CDP client (connect, navigate, wait, get HTML, manage tabs) 2. Wire into web adapter as browser fallback (HTTP+trafilatura fails → CDP+trafilatura) 3. Auto-start Chrome Debug if not running (shell out to chrome-debug/forage script) 4. Tab lifecycle — open, navigate, extract, close (don't litter Chrome Debug with orphan tabs) 5. Rename chrome-debug to forage across skill-chrome-log repo (script, app, commands) 6. Update mise skill to document Forage as the browser layer", "done": "mise fetch of a JS-rendered page uses CDP via Chrome Debug instead of webctl. Auth'd Google pages work via existing SSO session. chrome-log captures traffic from mise navigations. No webctl dependency."}, "status": "open", "order": 11, "created_at": "2026-02-06T20:11:41Z", "created_by": "spm1001", "parent": "mise-jy3", "waiting_for": null, "tactical": {"steps": ["Create adapters/cdp.py — thin CDP client (connect, navigate, wait, get HTML, manage tabs)", "Wire into web adapter as browser fallback (HTTP+trafilatura fails → CDP+trafilatura)", "Auto-start Chrome Debug if not running (shell out to chrome-debug/forage script)", "Tab lifecycle — open, navigate, extract, close (don't litter Chrome Debug with orphan tabs)", "Rename chrome-debug to forage across skill-chrome-log repo (script, app, commands)", "Update mise skill to document Forage as the browser layer"], "current": 2, "session": "/Users/modha/Repos/mise-en-space"}}
{"id": "mise-gelopa", "type": "action", "title": "Port apps-script from mcp-google-workspace", "brief": {"why": "Email exfiltration (Gmail attachments → Drive) is infrastructure that enables mise-en-space's 'Drive = canonical surface' philosophy. Currently lives in mcp-google-workspace which is being wound down.", "what": "1. Copy mcp-google-workspace/apps-script/ to mise-en-space/apps-script/ 2. Update apps-script/README.md paths if needed 3. Add to setup checklist in README.md 4. Add prerequisite row in CLAUDE.md 5. Verify itv-appscript-deploy still works from new location", "done": "apps-script/ exists in mise-en-space, setup docs mention it as a required step, can deploy from new location"}, "status": "open", "parent": "mise-tagemu", "order": 1, "created_at": "2026-01-29T22:32:57Z", "created_by": "spm1001", "waiting_for": null}
{"id": "mise-gifiku", "type": "action", "title": "Integration test for Gmail attachment extraction", "brief": {"why": "Current tests are unit-level; need to verify download → extract → deposit flow with real thread", "what": "Create test fixture with PDF attachment, write integration test that fetches thread and verifies PDF content is deposited", "done": "Integration test passes with real Gmail API call"}, "status": "done", "parent": "mise-4mj", "order": 5, "created_at": "2026-02-01T10:59:01Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Find a test thread with PDF attachment", "Write integration test that fetches thread and verifies PDF deposited", "Run test against real API"], "current": 3}, "done_at": "2026-02-09T06:14:03Z"}
{"id": "mise-gizige", "type": "action", "title": "Files can be moved between Drive folders", "brief": {"why": "v1 MCP had move_file capability. Users discovered gap when filing workflows broke. Subagent research confirmed this is a real need.", "what": "1. Add operation='move' handler in do tool 2. Accept source_id + dest_folder_id params 3. Port move logic from v1 (single-parent enforcement) 4. Return post-action cues (new parent folder, web_link) 5. Test with filing workflow", "done": "Files can be moved between Drive folders; filing skill workflows work"}, "status": "open", "parent": "mise-hijute", "order": 2, "created_at": "2026-01-31T22:07:37Z", "created_by": "spm1001", "waiting_for": null}
{"id": "mise-gocojo", "type": "action", "title": "Migrate remaining adapter tests to mock_api_chain", "brief": {"why": "4 adapter test files still use raw MagicMock chaining: test_sheets_adapter (7), test_docs_adapter (3), test_gmail_adapter (3), test_charts_adapter (4). Inconsistent patterns make tests harder to maintain.", "what": "1. Refactor test_sheets_adapter.py 2. Refactor test_docs_adapter.py 3. Refactor test_gmail_adapter.py 4. Refactor test_charts_adapter.py", "done": "All service-chain .execute.return_value/.side_effect patterns migrated to mock_api_chain. 4 non-service patterns remain intentionally: 2 batch callback mocks (Gmail) and 2 local mock_request objects (Slides) — these are structurally different from service chains."}, "status": "done", "parent": "mise-3uu", "order": 18, "created_at": "2026-02-09T08:52:01Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Refactor test_sheets_adapter.py", "Refactor test_docs_adapter.py", "Refactor test_gmail_adapter.py", "Refactor test_charts_adapter.py"], "current": 4}, "done_at": "2026-02-09T09:25:17Z"}
{"id": "mise-gofeBo", "type": "action", "title": "Decide v1 skill strategy", "brief": {"why": "mcp-google-workspace/skill-google-workspace still exists but references v1 tools. Either archive it or create a mise-specific skill.", "what": "After skill probe completes, decide: archive v1 skill / create mise skill / no skill needed", "done": "v1 skill archived or replaced"}, "status": "done", "parent": "mise-tuguzi", "order": 3, "created_at": "2026-02-01T10:59:54Z", "created_by": "spm1001", "waiting_for": null, "done_at": "2026-02-09T15:23:09Z"}
{"id": "mise-gtg", "title": "Factor Office file extraction into adapter", "type": "action", "status": "done", "done_at": "2026-01-24T20:28:57.425329Z", "brief": {"why": "DOCX/XLSX/PPTX extraction via Drive conversion is hardcoded in fetch.py. Should be adapter for testability.", "what": "## Current State\n\nIn tools/fetch.py:\n- `fetch_office()` handles DOCX, XLSX, PPTX\n- Uses upload → convert → export → delete pattern\n- Creates `_mise_temp_{file_id}` files in Drive\n\n## Problem\n\n1. Not testable without Drive access\n2. Pattern duplicates PDF's Drive conversion logic\n3. Temp file cleanup is best-effort (orphans accumulate)\n\n## Approach\n\nCreate `adapters/office.py`:\n\n```python\n@dataclass\nclass OfficeExtractionResult:\n    content: str\n    source_type: Literal[\"docx\", \"xlsx\", \"pptx\"]\n    converted_type: Literal[\"doc\", \"sheet\", \"slides\"]\n    warnings: list[str]\n\ndef extract_office_content(\n    file_path: Path,\n    service: Resource,\n    source_mime: str\n) -> OfficeExtractionResult:\n    \"\"\"\n    Extract Office file via Drive conversion.\n    \n    1. Upload to Drive with conversion\n    2. Export as text/markdown\n    3. Delete temp file (best effort)\n    \"\"\"\n```\n\n## Shared Infrastructure\n\nBoth PDF and Office use Drive conversion. Consider:\n- `adapters/drive_conversion.py` for shared upload/convert/export/delete\n- Used by both pdf.py and office.py\n\n## Acceptance Criteria\n\n- [ ] adapters/office.py exists with typed interface\n- [ ] fetch.py imports from adapter\n- [ ] Shared conversion logic factored out\n- [ ] Unit tests with mocked Drive responses\n- [ ] Temp file cleanup properly logged/warned", "done": "When complete"}, "created_at": "2026-01-24T20:09:22.044973Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-h6m", "title": "Adapter mocking infrastructure", "type": "action", "status": "done", "done_at": "2026-01-25T15:49:18.642701Z", "brief": {"why": "Adapter tests currently need real Google credentials. Add mocking infrastructure so tests run without hitting real APIs. Enables CI, faster tests, no credential management.", "what": "See title", "done": "When complete"}, "created_at": "2026-01-23T18:04:03.309992Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-hadabu", "type": "action", "title": "Mock chain validation catches renamed API methods", "brief": {"why": "mock_api_chain centralizes setup but MagicMock still silently creates new attributes. A renamed adapter method won't fail tests — it returns MagicMock instead of fixture data.", "what": "1. Test unittest.mock.seal() after mock setup in one adapter test file 2. If seal works with Google API chaining, add seal_service() helper to tests/helpers.py 3. Retrofit one test class as proof of concept", "done": "A test that renames a mock chain (e.g., files.get → files.get_media) fails immediately instead of passing silently"}, "status": "done", "parent": "mise-3uu", "order": 17, "created_at": "2026-02-09T08:51:58Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Test unittest.mock.seal() after mock setup in one adapter test file", "If seal works with Google API chaining, add seal_service() helper to tests/helpers.py", "Retrofit one test class as proof of concept"], "current": 3}, "done_at": "2026-02-09T09:15:33Z"}
{"id": "mise-hefoVu", "type": "outcome", "title": "Support text/plain files in fetch", "brief": {"why": "Plain text files like code.txt return 'unsupported type' - should just download and deposit", "what": "Add text/plain handler to fetch routing, download file, write to deposit folder", "done": "fetch('text-file-id') works for .txt, .csv, .json, etc"}, "status": "done", "order": 4, "created_at": "2026-01-29T21:47:24Z", "created_by": "spm1001", "done_at": "2026-01-29T22:20:56Z"}
{"id": "mise-hijute", "type": "outcome", "title": "Claude can act on Workspace, not just read it", "brief": {"why": "The MCP currently fetches and searches but can't organise. Users hit this in filing workflows (move), after creating docs (share/open), and when managing folders. The 3rd verb ('do') is designed but unbuilt.", "what": "1. Rename create→do with operation param 2. Move files between folders 3. Post-action cues on create 4. Rename files 5. Share/permission operations", "done": "do(operation=create|move|rename|share) works, with post-action cues on all operations"}, "status": "open", "parent": null, "order": 28, "created_at": "2026-02-09T23:15:48Z", "created_by": "spm1001"}
{"id": "mise-hnq", "title": "Add capture_slides_fixture.py script", "type": "action", "status": "done", "done_at": "2026-01-23T18:04:16.594043Z", "brief": {"why": "Consistent fixture capture workflow for slides, matching capture_fixtures.py pattern. Should fetch presentation and optionally sanitize.", "what": "See title", "done": "When complete"}, "created_at": "2026-01-23T17:31:18.063965Z", "created_by": "spm1001", "order": 1, "waiting_for": null}
{"id": "mise-i93", "title": "Reverse-engineer Drive video transcript API", "type": "action", "status": "done", "done_at": "2026-01-24T11:18:24.906334Z", "brief": {"why": "The /timedtext endpoint returns ASR transcripts in json3 format. Need to figure out: (1) Drive file ID → internal video ID mapping, (2) how authpayload is generated, (3) the redirect flow that establishes the session.", "what": "## Discovery (Jan 2026)\n\nEndpoint: `https://drive.google.com/u/0/timedtext?id={vid}&fmt=json3`\n\nSee: `bakeoff/video_transcript_discovery.md`\n\n## Approach\n\n1. Use webctl or Playwright to intercept network requests\n2. Trace the redirect chain (302 → 200)\n3. Find where authpayload comes from\n4. Test if Drive API exposes internal video ID\n\n## Alternative: claude-in-chrome\n\nThe Anthropic claude-in-chrome extension might provide dev tools access more naturally than webctl.", "done": "When complete"}, "created_at": "2026-01-24T08:53:49.194025Z", "created_by": "spm1001", "order": 1, "waiting_for": null}
{"id": "mise-jiseti", "type": "outcome", "title": "Gmail compose/draft scope in mise OAuth", "brief": {"why": "Audit session hit this: tried to create a Gmail draft programmatically and got 403 insufficient scopes. Current mise token is read-only for Gmail — can search and fetch threads but can't create drafts or send. Useful for drafting emails from audit findings, research summaries, etc.", "what": "1. Add gmail.compose scope to OAuth flow in auth.py 2. Update token refresh to include new scope 3. Test draft creation via gmail.users().drafts().create() 4. Document the new capability", "done": "Can create Gmail drafts via mise's OAuth token. Existing read-only flows still work. Token refresh handles the new scope without re-auth (or re-auth is documented if unavoidable)."}, "status": "open", "order": 29, "created_at": "2026-02-12T08:32:26Z", "created_by": "spm1001"}
{"id": "mise-jodeja", "type": "action", "title": "Pre-exfil attachment detection", "brief": {"why": "Drive indexes PDF content via fullText, Gmail doesn't. Background extractor saves attachments to Drive. Fetch should use indexed copy when available.", "what": "1. Config for Email Attachments folder ID (env var or discover) 2. Query Drive for attachment by name in folder 3. Use Drive copy if found, else Gmail fallback", "done": "Looks up attachments in Drive folder, uses Drive copy when found, graceful fallback when not"}, "status": "done", "parent": "mise-4mj", "order": 2, "created_at": "2026-01-29T22:14:34Z", "created_by": "spm1001", "waiting_for": null, "done_at": "2026-02-08T18:40:32Z"}
{"id": "mise-jonaha", "type": "action", "title": "Wire pre-exfil lookup in fetch_gmail", "brief": {"why": "Pre-exfil optimization skips Gmail download for already-indexed files", "what": "Call lookup_exfiltrated() in fetch_gmail before downloading attachments. If file exists in Drive with Message ID match, fetch from Drive instead of Gmail.", "done": "fetch_gmail checks pre-exfil folder, uses Drive file when available"}, "status": "done", "parent": "mise-4mj", "order": 4, "created_at": "2026-02-01T10:59:00Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Trace current attachment handling in fetch_gmail/fetch tool", "Add lookup_exfiltrated() call before attachment download", "Route matched attachments through Drive fetch instead of Gmail download", "Test with unit test (mock lookup_exfiltrated)", "Verify graceful fallback when no exfil folder"], "current": 5}, "done_at": "2026-02-08T18:44:43Z"}
{"id": "mise-jutike", "type": "action", "title": "Create purpose-built test doc with rich comments", "brief": {"why": "Current test_doc_with_comments_id reuses test_doc_id — works but lacks dedicated edge cases", "what": "Create Google Doc in test folder with: threaded replies, resolved/unresolved mix, @mentions, long anchor quotes, empty anchors (like DOCX)", "done": "Fixture exists with predictable comment patterns for regression testing"}, "status": "done", "parent": "mise-3uu", "order": 7, "created_at": "2026-02-01T10:59:21Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Create Google Doc in test folder with sections to anchor comments on", "Add comments via Drive API: threaded replies, resolved+unresolved, @mention, long anchor, empty anchor", "Capture fixture with capture_fixtures.py", "Verify fixture has predictable comment patterns for regression"], "current": 4}, "done_at": "2026-02-09T11:26:29Z"}
{"id": "mise-jvz", "title": "Wire fetch tool — with pre-exfil detection", "type": "action", "status": "done", "done_at": "2026-01-23T22:33:09.699182Z", "brief": {"why": "Fetch content to filesystem. Auto-detects ID type, checks for pre-exfiltrated attachments.", "what": "## Signature\n\nfetch(id: str) -> dict\n\n## Response Shape\n\n{\n  \"path\": \"~/.mcp-workspace/account/drive/abc123.md\",\n  \"format\": \"markdown\",\n  \"metadata\": {\"title\": \"...\", \"mimeType\": \"...\", \"modified\": \"...\"}\n}\n\n## ID Auto-Detection\n\n1. If looks like Gmail URL → extract thread ID\n2. If looks like Drive URL → extract file ID\n3. If hex-ish (194ac68f...) → Gmail thread/message\n4. Otherwise → Drive file ID\n\n## Pre-Exfiltration Detection\n\nBefore downloading Gmail attachment:\n1. Check \"Email Attachments\" folder for matching file\n2. Match by: filename + size + approximate date\n3. If found → fetch from Drive (already indexed, searchable)\n4. If not → download from Gmail (3x faster than Drive for same binary)\n\n## Routing by Type\n\n- Google Doc → docs extractor → markdown\n- Google Sheet → sheets extractor → CSV  \n- Google Slides → slides extractor → structured text\n- Gmail thread → gmail extractor → cleaned text\n- PDF → markitdown → markdown\n- Office → Drive conversion → appropriate extractor\n- Binary → download to workspace, return path\n\n## Acceptance Criteria\n\n- [ ] Auto-detects ID type\n- [ ] Handles Gmail URLs\n- [ ] Checks pre-exfil folder before Gmail download\n- [ ] Routes to correct extractor\n- [ ] Returns path, not content\n\n## URL Handling (REQUIRED)\n\nAccept Gmail URLs and convert to thread ID:\n- https://mail.google.com/mail/u/0/#inbox/18f4a... → extract thread_id\n- Port the URL extraction logic from v1 validation.py\n", "done": "When complete"}, "created_at": "2026-01-23T07:25:15.084528Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-jy3", "title": "Post-release: richer extraction features", "type": "outcome", "status": "open", "brief": {"why": "Enhancements. Visual content (thumbnails, images) available when useful. Smarter extraction.", "what": "## What Success Looks Like\n\nClear decisions on whether to port v1 features. Each feature either: ported, declined with rationale, or deferred to Someday.\n\n## Acceptance Criteria\n\n- [ ] PDF thumbnail decision made (port or decline)\n- [ ] PDF visual extraction strategy decided\n- [ ] Pre-exfil detection implemented OR deferred\n- [ ] Deposit cleanup strategy decided\n\n## Children\n\n- mise-q7j: Evaluate v1 PDF thumbnails (research)\n- mise-ogf: PDF visual extraction strategy (decision)\n- mise-52d.4: Pre-exfil attachment detection\n- mise-9jl: Deposit cleanup strategy\n\n## Why This Matters\n\nv1 had features we rushed past. This epic ensures we consciously decide rather than accidentally omit.", "done": "When complete"}, "created_at": "2026-01-24T20:16:53.534947Z", "created_by": "spm1001", "order": 5}
{"id": "mise-k6g", "title": "Factor PDF extraction into adapter", "type": "action", "status": "done", "done_at": "2026-01-24T20:28:57.330853Z", "brief": {"why": "PDF hybrid extraction logic (markitdown → Drive fallback) is hardcoded in fetch.py. Should be an adapter for testability and reuse.", "what": "## Current State\n\nIn tools/fetch.py:\n- `fetch_pdf()` function handles all PDF logic\n- MARKITDOWN_MIN_CHARS = 500 hardcoded constant\n- Hybrid strategy: try markitdown, fall back to Drive if <500 chars\n\n## Problem\n\n1. Not testable without real files (no adapter abstraction)\n2. Threshold not parameterized\n3. Logic entangled with file writing (workspace concerns)\n\n## Approach\n\nCreate `adapters/pdf.py`:\n\n```python\n@dataclass\nclass PdfExtractionResult:\n    content: str\n    method: Literal[\"markitdown\", \"drive\"]\n    char_count: int\n    warnings: list[str]\n\ndef extract_pdf_content(\n    file_path: Path | None = None,\n    file_id: str | None = None,\n    service: Resource | None = None,\n    min_chars_threshold: int = 500\n) -> PdfExtractionResult:\n    \"\"\"\n    Hybrid PDF extraction.\n    \n    If file_path provided: use markitdown directly\n    If file_id provided: download then markitdown, fall back to Drive conversion\n    \"\"\"\n```\n\nMove from fetch.py:\n- `_extract_with_markitdown()` \n- `_extract_with_drive_conversion()`\n- Threshold constant\n\n## Acceptance Criteria\n\n- [ ] adapters/pdf.py exists with typed interface\n- [ ] fetch.py imports from adapter (thin wiring only)\n- [ ] min_chars_threshold is parameterized\n- [ ] Unit tests with mocked markitdown responses\n- [ ] Integration test with real PDF", "done": "When complete"}, "created_at": "2026-01-24T20:09:12.256743Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-k80", "title": "Test MCP resources in real Claude session", "type": "action", "status": "done", "brief": {"why": "MCP resources are registered but not verified in actual use. Need to confirm Claude can read mise:// URIs.", "what": "## Test Plan\n\n1. Start mise-en-space MCP (replace v1 or run alongside)\n2. In Claude session, request resource: \"Read mise://docs/fetch\"\n3. Verify content returns correctly\n4. Test all 5 resources:\n   - mise://docs/overview\n   - mise://docs/search\n   - mise://docs/fetch\n   - mise://docs/create\n   - mise://docs/workspace\n\n## Acceptance Criteria\n- [ ] Claude can read each resource\n- [ ] Content matches what's in server.py\n- [ ] No errors or empty responses", "done": "When complete"}, "created_at": "2026-01-25T17:28:40.189716Z", "created_by": "spm1001", "order": 1, "parent": "mise-6kh", "waiting_for": null, "done_at": "2026-01-31T22:06:46Z"}
{"id": "mise-k97", "title": "Investigate Google Groups content access", "type": "action", "status": "done", "done_at": "2026-01-24T21:27:09.680923Z", "brief": {"why": "Research how to fetch Google Groups conversation archives. Individual Gmail inboxes aren't reliable (subscriptions vary, digest mode, membership changes). Need to access group archives directly.", "what": "## Goal\n\nEnable `fetch(group_id)` or `search(source=\"groups\")` to access Google Groups discussions.\n\n## Research Questions\n\n1. **Groups Migration API** — Can it read/export posts without admin?\n   - Docs: https://developers.google.com/admin-sdk/groups-migration\n   - Test: Try to list/export from a group we have access to\n\n2. **groups.google.com scraping** — What's the DOM structure?\n   - Auth: Does browser session (webctl) work?\n   - Pagination: How are threads listed?\n   - Content: Can we get full thread content?\n\n3. **Cloud Identity API** — Any content access?\n   - Docs: https://cloud.google.com/identity/docs/groups\n\n4. **Workspace admin approaches** — What's possible with elevated access?\n\n## Acceptance Criteria\n\n- [ ] Document which API/approach works (or confirm none do)\n- [ ] If viable: create follow-up bead with implementation design\n- [ ] If not viable: document why and close\n\n## Test Groups\n\n- MIT team groups (if accessible)\n- Public Google Groups (for unauthenticated testing)", "done": "When complete"}, "created_at": "2026-01-24T20:40:48.224167Z", "created_by": "spm1001", "order": 1, "parent": "mise-6ku", "waiting_for": null}
{"id": "mise-kaRuro", "type": "action", "title": "Sanitized test fixtures", "brief": {"why": "Test fixtures contain real data (ITV budget figures, email addresses). Required before open-sourcing or sharing.", "what": "Create sanitized fixture versions with fake data that preserves structure", "done": "All fixtures sanitized, no real PII/business data, structure preserved for tests"}, "status": "done", "parent": "mise-3uu", "order": 4, "created_at": "2026-01-29T22:14:41Z", "created_by": "spm1001", "waiting_for": null, "done_at": "2026-02-09T07:20:08Z"}
{"id": "mise-kabaGi", "type": "action", "title": "Deposit folder cleanup strategy", "brief": {"why": "mise-fetch/ folders accumulate with no cleanup — unbounded growth over time.", "what": "1. Add cleanup_after timestamp to manifest.json 2. Add cleanup function to workspace/manager.py 3. Document cleanup approach", "done": "manifest.json has cleanup_after field, cleanup function exists, documented"}, "status": "done", "parent": "mise-jy3", "order": 3, "created_at": "2026-01-29T22:14:45Z", "created_by": "spm1001", "waiting_for": null, "done_at": "2026-02-09T23:15:31Z"}
{"id": "mise-kamotu", "type": "action", "title": "Add unit tests for cues output", "brief": {"why": "cues block added to all 15 fetch return sites but no tests assert on content. Existing 992 tests pass because they predate cues. Untested code riding on tested code.", "what": "1. Test fetch_doc returns cues with correct open_comment_count 2. Test fetch_gmail includes participants list 3. Test email_context is null (not absent) when no email trail 4. Test files list matches actual deposit contents", "done": "At least 4 new tests covering cues contract for doc, gmail, search preview"}, "status": "done", "parent": "mise-jy3", "order": 13, "created_at": "2026-02-09T20:44:17Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Fix 4 critical-path items from titans review", "Fix cherry-picked lower-priority items", "Add unit tests for cues output (kamotu)", "Add unit tests for search preview output"], "current": 4}, "done_at": "2026-02-09T21:08:28Z"}
{"id": "mise-kineza", "type": "action", "title": "Benchmark and document expected latencies", "brief": {"why": "Speed is a nagging concern — unclear if it's MCP startup, search latency, extraction time, or all three. Team will notice if it's slow but won't diagnose why.", "what": "1. Measure MCP server startup time 2. Benchmark search (Drive, Gmail, both) 3. Benchmark fetch for each content type (doc, sheet, slides, PDF, web) — run live, don't reuse old numbers 4. Document expected latencies in README or skill 5. Identify worst offenders and file optimisation items if needed", "done": "README or skill has 'what to expect' section with typical latencies. Worst-case paths identified."}, "status": "done", "parent": "mise-naviho", "order": 7, "created_at": "2026-02-07T18:57:14Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Measure MCP server startup time", "Benchmark search (Drive, Gmail, both)", "Benchmark fetch for each content type (doc, sheet, slides, PDF, web)", "Document expected latencies in README or skill", "Identify worst offenders and file optimisation items if needed"], "current": 5}, "done_at": "2026-02-09T06:30:00Z"}
{"id": "mise-kivati", "type": "action", "title": "Investigate slides thumbnail parallelism", "brief": {"why": "Slides fetch for 7 slides takes ~6s. Thumbnails are fetched sequentially (~0.5s each). Google disabled HTTP batch for editor APIs in 2022, but concurrent individual requests might still work.", "what": "1. Test concurrent.futures.ThreadPoolExecutor for parallel getThumbnail calls 2. Verify Google doesn't rate-limit concurrent thumbnail requests 3. If parallel works, measure improvement 4. If rate-limited, document the constraint", "done": "Either: thumbnail fetch is parallel and slides benchmark drops by 40%+, or documented that Google rate-limits concurrent requests."}, "status": "done", "parent": "mise-weduje", "order": 3, "created_at": "2026-02-09T06:37:12Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Test concurrent.futures.ThreadPoolExecutor for parallel getThumbnail calls", "Verify Google doesn't rate-limit concurrent thumbnail requests", "If parallel works, measure improvement", "If rate-limited, document the constraint"], "current": 4}, "done_at": "2026-02-09T13:42:42Z"}
{"id": "mise-kojiti", "type": "action", "title": "Add symlink setup to README", "brief": {"why": "Contributors cloning fresh need to create ~/.claude/skills/mise symlink manually", "what": "Add setup instructions to README for skill symlink", "done": "README has clear instructions for linking skill after clone"}, "status": "done", "order": 4, "created_at": "2026-02-01T20:05:48Z", "created_by": "spm1001", "parent": "mise-naviho", "waiting_for": null, "done_at": "2026-02-07T21:17:07Z"}
{"id": "mise-lahero", "type": "action", "title": "Implement single-attachment fetch API", "brief": {"why": "Office files are skipped in eager extraction (5-10s each). Need explicit fetch path.", "what": "Add fetch(message_id, attachment=filename) API to download and extract a specific Office attachment on demand", "done": "Can fetch individual PPTX/DOCX/XLSX from Gmail with extraction"}, "status": "done", "parent": "mise-4mj", "order": 6, "created_at": "2026-02-01T10:59:02Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Add attachment param to server.py", "Add fetch_attachment + routing in tools/fetch.py", "Update skipped_office_hint", "Write unit tests", "Update CLAUDE.md design decision"], "current": 5}, "done_at": "2026-02-08T21:36:21Z"}
{"id": "mise-lajeke", "type": "outcome", "title": "Existing Google Docs can be edited, not just created", "brief": {"why": "During GCloud audit, needed to prepend an exec summary to an existing doc. Mise's create tool makes new docs but can't edit them. Had to write a throwaway Python script using the Docs API directly via mise's token. The token already has auth/documents scope — the capability is there, just not exposed.", "what": "1. Add an update/patch tool to mise MCP (insertText, replaceText, or full content replacement) 2. Decide granularity: surgical edits (batchUpdate) vs wholesale replace (simpler but loses formatting) 3. Consider also supporting Sheets and Slides editing for parity 4. Update skill docs to reflect new capability", "done": "Can edit an existing Google Doc through mise MCP tools without writing throwaway Python scripts. At minimum: prepend/append text, replace content. Ideally: insertText at index for surgical edits."}, "status": "open", "order": 30, "created_at": "2026-02-12T08:47:20Z", "created_by": "spm1001"}
{"id": "mise-lakono", "type": "action", "title": "Route non-PDF binary web content to extractors", "brief": {"why": "Web URLs serving DOCX/XLSX/PPTX (SharePoint downloads, presigned S3 URLs, file hosting) still hit trafilatura HTML extraction and produce garbage. Only application/pdf is handled.", "what": "1. Add Office MIME types to BINARY_CONTENT_TYPES in adapters/web.py 2. Add routing in fetch_web() per content-type — application/vnd.openxmlformats-officedocument.* maps to Office extractors 3. Wire _fetch_web_office() similar to _fetch_web_pdf() — save raw_bytes to temp file, call fetch_and_extract_office with appropriate OfficeType 4. Test with mocked responses for each Office type", "done": "fetch('https://example.com/report.docx') extracts markdown. fetch('https://example.com/data.xlsx') extracts CSV. Unit tests for each Office MIME type."}, "status": "done", "parent": "mise-jy3", "order": 9, "created_at": "2026-02-07T16:18:00Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Add Office MIME types to BINARY_CONTENT_TYPES in adapters/web.py", "Add routing in fetch_web() per content-type — application/vnd.openxmlformats-officedocument.* maps to Office extractors", "Wire _fetch_web_office() similar to _fetch_web_pdf() — save raw_bytes to temp file, call fetch_and_extract_office with appropriate OfficeType", "Test with mocked responses for each Office type"], "current": 4}, "done_at": "2026-02-07T18:23:25Z"}
{"id": "mise-lakusu", "type": "action", "title": "Arc tactical stale-state visibility", "brief": {"why": "arc done doesn't clear tactical steps. Next arc work on a different action fails until manual arc work --clear. Hit twice during mise-tuguzi session — friction that breaks flow.", "what": "1. Diagnose whether arc done should auto-clear tactical 2. Fix in arc CLI (clear on done, or clear-and-activate on work) 3. Remove need for manual --clear workaround", "done": "arc done X && arc work Y succeeds without manual --clear step"}, "status": "done", "parent": null, "order": 2, "created_at": "2026-02-09T06:48:32Z", "created_by": "spm1001", "waiting_for": null, "done_at": "2026-02-09T16:46:52Z"}
{"id": "mise-lft", "title": "Search deposits results to file instead of inline JSON", "type": "action", "status": "done", "brief": {"why": "Search should deposit results to mise-fetch/search--{query}/results.json instead of returning JSON inline. More token-efficient for calling Claude, especially when firing multiple searches.", "what": "## Approach\n\n1. Create deposit folder: `mise-fetch/search--{slugified-query}--{timestamp}/`\n2. Write results.json with drive_results + gmail_results\n3. Return {path, drive_count, gmail_count} instead of full JSON\n\n## Already done\n- contentSnippet in Drive results ✅\n- attachment_names in Gmail results ✅", "done": "When complete"}, "created_at": "2026-01-25T19:14:20.312794Z", "created_by": "spm1001", "order": 2, "parent": "mise-naviho", "waiting_for": null, "done_at": "2026-02-07T21:11:03Z"}
{"id": "mise-loMuzu", "type": "outcome", "title": "Activity fixture capture", "brief": {"why": "Activity adapter unit tests only cover models, not parsing logic. Need fixtures/activity/ with real API responses to test _parse_actor, _parse_target, _parse_comment_action.", "what": "Add capture_activity_fixtures() to scripts/capture_fixtures.py. Capture sample comment activities and file activities. Sanitize email addresses.", "done": "fixtures/activity/comment_activities.json and file_activities.json exist with realistic test data"}, "status": "done", "order": 16, "created_at": "2026-01-31T17:58:21Z", "created_by": "spm1001", "done_at": "2026-02-01T10:58:31Z"}
{"id": "mise-lodipa", "type": "outcome", "title": "Implement single-attachment fetch API", "brief": {"why": "Office files are skipped in eager extraction (5-10s each). Need explicit fetch path.", "what": "Add fetch(message_id, attachment=filename) API to download and extract a specific Office attachment on demand", "done": "Can fetch individual PPTX/DOCX/XLSX from Gmail with extraction"}, "status": "done", "order": 10, "created_at": "2026-01-29T23:25:59Z", "created_by": "spm1001", "done_at": "2026-02-01T10:58:29Z"}
{"id": "mise-lorafi", "type": "action", "title": "Contributing guide and GitHub issue templates", "brief": {"why": "Team (mostly Claude users) needs clear path to contribute, report bugs, and request features. Contributing agents need posture guidance: file issues not PRs, don't modify architecture, layer rules", "what": "1. CONTRIBUTING.md aimed at Claude agents (works for humans too) covering: posture, test commands, layer rules, filing good bug reports 2. GitHub issue templates (bug, feature, question) 3. Branch protection on main", "done": "A teammate's Claude can clone, orient, run tests, and file an actionable bug report following conventions"}, "status": "done", "parent": "mise-naviho", "order": 5, "created_at": "2026-02-07T18:50:32Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["CONTRIBUTING.md aimed at Claude agents (works for humans too) covering: posture, test commands, layer rules, filing good bug reports", "GitHub issue templates (bug, feature, question)", "Branch protection on main"], "current": 3}, "done_at": "2026-02-07T22:58:27Z"}
{"id": "mise-lusome", "type": "action", "title": "Activity API integration tests", "brief": {"why": "Activity adapter has no real API tests — only model unit tests. Need to verify retry wiring, pagination behavior, and error handling against real API.", "what": "Create tests/integration/test_activity.py with tests for search_comment_activities and get_file_activities. Use real credentials, mark with @pytest.mark.integration.", "done": "Integration tests exist, can run with uv run pytest -m integration"}, "status": "done", "parent": "mise-3uu", "order": 5, "created_at": "2026-02-01T10:59:19Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Read existing integration test patterns", "Write integration tests for search_comment_activities and get_file_activities", "Run tests against real API and verify"], "current": 3}, "done_at": "2026-02-09T10:18:13Z"}
{"id": "mise-mafoce", "type": "action", "title": "Mock helper for Google API tests", "brief": {"why": "MagicMock chaining (mock_service.files().get().execute.return_value) is brittle — if adapter code changes call pattern, mock silently returns MagicMock instead of fixture data. Multiple test files duplicate this pattern.", "what": "Create tests/helpers.py with mock_google_service() that takes method chain + response, validates the chain at test time. Refactor existing adapter tests to use it.", "done": "All adapter test files use shared helper. A refactored adapter call pattern causes a test failure, not a silent pass."}, "status": "done", "parent": "mise-3uu", "order": 13, "created_at": "2026-02-09T07:20:16Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Survey existing Google API mock patterns across test files", "Create tests/helpers.py with mock_google_service helper", "Refactor adapter tests to use the helper"], "current": 3}, "done_at": "2026-02-09T08:44:10Z"}
{"id": "mise-mavoze", "type": "action", "title": "Adapt mise skill for Pi/CLI (no MCP)", "brief": {"why": "mise skill assumes MCP tools (mcp__mise__search/fetch/create) are available. On Pi, CLI-only setups, or sessions without the MCP configured, the skill's guidance is useless — Claude can't call tools that don't exist.", "what": "1. Identify which skill guidance is MCP-dependent vs universal (search syntax, exploration patterns) 2. Add fallback patterns for non-MCP environments (curl, direct API, manual steps) 3. Test on CLI-only session", "done": "Skill provides useful guidance even without MCP tools — Claude knows what to do differently"}, "status": "open", "parent": null, "order": 5, "created_at": "2026-02-09T15:48:43Z", "created_by": "spm1001", "waiting_for": null}
{"id": "mise-mawoju", "type": "outcome", "title": "Docs can be overwritten in-place from markdown without human copy-paste", "brief": {"why": "During GCloud audit, updating an existing Google Doc required pulling as markdown, editing locally, opening in Sublime, and having the user manually paste it back. The Docs API supports full content replacement via batchUpdate (delete all + insertText), and mise's token already has auth/documents scope. This is a different shape from mise-lajeke (surgical edits) — this is wholesale markdown-to-doc replacement, preserving the file ID and sharing.", "what": "1. Add an overwrite/replace tool to mise MCP that takes markdown content and a doc ID 2. Implementation: use Docs API batchUpdate to delete range(1, end) then insertText the new content at index 1 3. Optionally re-apply heading styles by parsing markdown headers (## → Heading 2 etc.) 4. Ensure shared drive docs work (supportsAllDrives) 5. Test round-trip: create → fetch → edit markdown → overwrite → fetch again", "done": "Can replace the full content of an existing Google Doc via mise MCP tool, from markdown, without human intervention. File ID, sharing, and location are preserved. Heading styles are applied. Works on shared drives."}, "status": "open", "order": 31, "created_at": "2026-02-12T08:55:47Z", "created_by": "spm1001"}
{"id": "mise-mecebu", "type": "action", "title": "Activity fixtures survive re-capture without manual PII cleanup", "brief": {"why": "Activity fixtures contain file titles and team drive names that the sanitizer doesn't catch. Re-running capture_fixtures.py --sanitize leaves real data in activity fixtures — manual find-replace was needed for the initial capture.", "what": "Add activity-specific sanitization patterns to sanitize_fixtures.py: file title replacement, team drive name replacement, people ID normalization. Verify by re-running capture + sanitize and checking output.", "done": "uv run python scripts/capture_fixtures.py --sanitize produces activity fixtures with no real file titles, team drive names, or unsanitized people IDs"}, "status": "done", "parent": "mise-3uu", "order": 20, "created_at": "2026-02-09T10:41:17Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Add file/folder title sanitization to sanitize_fixtures.py", "Re-capture and sanitize activity fixtures", "Verify no real data remains"], "current": 3}, "done_at": "2026-02-09T11:56:08Z"}
{"id": "mise-menifo", "type": "action", "title": "Shared constant for extraction_failed cue marker", "brief": {"why": "tools/fetch/web.py detects extraction failure by string-matching '*Content extraction failed for' against extractor output. If extractors/web.py changes the stub wording, the cue silently breaks. Cross-layer test catches it now but a shared constant would be better.", "what": "1. Add EXTRACTION_FAILED_MARKER constant to models.py or extractors/web.py 2. Import in both extractor and tool layer 3. Verify cross-layer test still passes", "done": "Both layers reference the same constant. Changing the marker string requires changing it in one place only."}, "status": "open", "parent": "mise-jy3", "order": 23, "created_at": "2026-02-13T10:59:58Z", "created_by": "spm1001", "waiting_for": null}
{"id": "mise-mii", "title": "Handle orphaned _mise_temp_* files", "type": "action", "status": "done", "done_at": "2026-01-25T15:46:57.651295Z", "brief": {"why": "If Drive delete fails during PDF/Office conversion, orphan temp files accumulate. Options: (1) Catch delete errors and log for manual cleanup, (2) Add cleanup job that finds _mise_temp_* files older than 1 hour, (3) Use Drive's trash instead of permanent delete.", "what": "See title", "done": "When complete"}, "created_at": "2026-01-24T19:56:14.172851Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-milako", "type": "action", "title": "Sharper blind test: preview as triage replacement", "brief": {"why": "Wijupo blind test used a 'comprehensive research' prompt which naturally requires reading full files. The test confirmed preview works for field accuracy but didn't test whether preview alone enables triage decisions. Need a triage-only prompt to test this.", "what": "1. Design prompt that asks 'which of these should I fetch' not 'fetch everything and summarise' 2. Run blind test with fresh Claude 3. Observe: does preview alone drive fetch decisions without reading deposited file?", "done": "Blind test with triage prompt confirms preview sufficient for pick-and-fetch workflow"}, "status": "open", "parent": "mise-jy3", "order": 20, "created_at": "2026-02-09T23:19:57Z", "created_by": "spm1001", "waiting_for": null}
{"id": "mise-mkb", "title": "Wire help tool — self-documentation", "type": "action", "status": "done", "done_at": "2026-01-23T07:43:25.311309Z", "brief": {"why": "Self-documentation tool. Returns usage info for the MCP.", "what": "## Signature\n\nhelp(topic: str = None) -> str\n\n## Topics\n\n- None → overview of all verbs\n- \"search\" → search usage and examples\n- \"fetch\" → fetch usage, format routing\n- \"create\" → create usage\n- \"formats\" → what formats are supported\n\n## Acceptance Criteria\n\n- [ ] Default help is concise overview\n- [ ] Topic-specific help exists for each verb\n- [ ] Examples included", "done": "When complete"}, "created_at": "2026-01-23T07:25:30.899606Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-muceki", "type": "action", "title": "Add mise://docs/cross-source resource", "brief": {"why": "Document the bounce-between-sources pattern and filename: operator", "what": "New MCP resource with cross-source workflow patterns", "done": "Resource accessible and accurate"}, "status": "done", "parent": "mise-cunufu", "order": 1, "created_at": "2026-01-29T21:12:20Z", "created_by": "spm1001", "waiting_for": null, "done_at": "2026-01-29T21:13:13Z"}
{"id": "mise-muwetu", "type": "action", "title": "Parallel search integration test", "brief": {"why": "Parallel search (mise-cohato) only has unit test coverage. Unit tests mock adapters so they can't catch threading issues — token refresh races, httplib2 thread safety, or futures not actually running concurrently.", "what": "1. Write integration test that times search with both sources 2. Assert total time < 2x slower single source (proves concurrency) 3. Run 5 times to check for intermittent thread issues", "done": "Integration test proves parallel search completes in under 1.5s and doesn't race on auth"}, "status": "done", "parent": "mise-3uu", "order": 12, "created_at": "2026-02-09T06:48:26Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Write integration test that times search with both sources", "Assert total time < 2x slower single source (proves concurrency)", "Run 5 times to check for intermittent thread issues"], "current": 3}, "done_at": "2026-02-09T10:23:20Z"}
{"id": "mise-naviho", "type": "outcome", "title": "Ship to team", "brief": {"why": "Team has mixed technical ability. Need solid ergonomics, clear docs, and good contribution patterns before they and their Claudes start using it.", "what": "1. Fix deposit cwd bug 2. Search deposits to file 3. Rewrite README 4. Add symlink setup to README 5. Contributing guide + issue templates 6. AGENTS.md for visiting Claudes", "done": "Teammate can: install, search, fetch, read deposits in their cwd. Their Claude can: file bugs via GitHub issues following template."}, "status": "done", "order": 1, "created_at": "2026-02-07T18:50:23Z", "created_by": "spm1001", "done_at": "2026-02-09T06:30:15Z", "waiting_for": null}
{"id": "mise-nfh", "title": "Port gmail extractor", "type": "action", "status": "done", "done_at": "2026-01-23T15:22:31.74465Z", "brief": {"why": "Port gmail.py extraction (1126 lines). Signature stripping, HTML→markdown, thread assembly.", "what": "## What to Port\n\nFrom v1 tools/gmail.py:\n- Signature stripping (talon library, 0.01ms per message)\n- HTML → markdown (markitdown, NOT Google Docs API)\n- Thread assembly from messages\n- Quoted reply removal\n\n## Key Learning (from V2.md)\n\nHTML→markdown was the bottleneck (10s for 64KB email).\nNow using markitdown: ~100ms. Keep this fix.\n\n## Signature\n\nextract_thread(thread_response: dict, messages: list[dict]) -> str\nextract_message(message_response: dict) -> str\n\n## Acceptance Criteria\n\n- [ ] extractors/gmail.py exists\n- [ ] Signature stripping works\n- [ ] HTML converted via markitdown (fast path)\n- [ ] Unit test with fixture passes", "done": "When complete"}, "created_at": "2026-01-23T07:24:28.743738Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-nofifu", "type": "action", "title": "Test for HTML body with PDF Content-Type", "brief": {"why": "A misconfigured CDN could return content_type: application/pdf with an HTML body. Current code would pass HTML bytes to markitdown, get <500 chars, fall back to Drive conversion, and produce a confusing extraction error that doesn't mention the real problem.", "what": "1. Add test: mock WebData with content_type=application/pdf but raw_bytes containing HTML 2. Verify error message mentions content mismatch 3. Consider adding PDF magic bytes check (%PDF-) in _fetch_web_pdf before calling extract_pdf_content", "done": "Unit test covers misleading Content-Type. Error message is actionable."}, "status": "done", "parent": "mise-3uu", "order": 8, "created_at": "2026-02-07T16:23:13Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Read _fetch_web_pdf in tools/fetch.py to understand current PDF routing", "Add test: HTML bytes with application/pdf Content-Type", "Add PDF magic bytes check (%PDF-) before extraction", "Run tests"], "current": 4}, "done_at": "2026-02-09T07:01:21Z"}
{"id": "mise-ogf", "title": "PDF visual extraction strategy", "type": "action", "status": "open", "brief": {"why": "Decide when PDFs need page images vs text extraction. Unlike Slides, PDFs don't have semantic markers (charts, shapes). Options: always text, always images, hybrid based on text density, user parameter.", "what": "## The Question\n\nUnlike Slides (which have semantic markers: charts, shapes, text boxes), PDFs are opaque. When should we render page images vs extract text?\n\n## Options\n\n1. **Always text** — Simple, fast. Miss visual content.\n2. **Always images** — Complete, expensive. Wastes tokens on text-heavy PDFs.\n3. **Hybrid by density** — Measure text/page ratio. Low text = render image.\n4. **User parameter** — Let caller decide. `fetch(id, visual=true)`\n\n## Research Needed\n\n- What % of user's PDFs are visual-heavy (presentations, scanned docs)?\n- What's the token cost difference? (text ~500 tokens vs image ~1000+)\n- Does markitdown already signal \"low content extracted\"?\n\n## Acceptance Criteria\n\n- [ ] Decision documented in CLAUDE.md\n- [ ] Implementation matches decision (or explicitly deferred)", "done": "When complete"}, "created_at": "2026-01-24T22:24:12.022384Z", "created_by": "spm1001", "order": 1, "parent": "mise-jy3", "waiting_for": null}
{"id": "mise-p01", "title": "Port sheets.py — prove the pattern", "type": "action", "status": "done", "brief": {"why": "Smallest extractor (138 lines, 1 function). Port to pure function to validate architecture.", "what": "## Why sheets.py First\n\n- 138 lines, single function `read_sheets_as_csv()`\n- Clear input → output\n- If this works, docs.py/slides.py/gmail.py follow same pattern\n\n## Porting Steps\n\n1. Copy extraction logic from v1 tools/sheets.py\n2. Remove `get_sheets_service()` call\n3. Change signature: `extract_sheets_csv(sheets_response: dict) -> str`\n4. Write unit test with fixture\n5. Write integration test with real sheet\n\n## Acceptance Criteria\n\n- [ ] extractors/sheets.py exists\n- [ ] Pure function signature\n- [ ] Unit test passes\n- [ ] Integration test passes", "done": "When complete"}, "created_at": "2026-01-20T22:10:34.217867Z", "created_by": "spm1001", "order": 1, "waiting_for": null, "done_at": "2026-01-29T20:45:23Z"}
{"id": "mise-peliwo", "type": "outcome", "title": "Decide v1 skill strategy", "brief": {"why": "mcp-google-workspace/skill-google-workspace still exists but references v1 tools. Either archive it or create a mise-specific skill.", "what": "After skill probe (mise-Zoluca) completes, decide: archive v1 skill / create mise skill / no skill needed", "done": "v1 skill archived or replaced"}, "status": "done", "order": 22, "created_at": "2026-01-31T20:49:52Z", "created_by": "spm1001", "done_at": "2026-02-01T10:58:34Z"}
{"id": "mise-pujege", "type": "action", "title": "Update mise skill for Gmail deposit format", "brief": {"why": "Gmail deposits now use file pointers instead of inline text (a0a7a45). The mise skill's Gmail section doesn't mention that extracted attachments are separate files that need explicit Read. A calling Claude may not discover the .pdf.md files.", "what": "Update mise SKILL.md Gmail section to mention: 1. Extracted attachments are separate files (filename.md) 2. content.md has pointers, not full text 3. Read the .pdf.md file when you need attachment content", "done": "Mise skill documents the Gmail deposit structure including separate attachment files"}, "status": "done", "parent": "mise-4mj", "order": 10, "created_at": "2026-02-08T21:22:32Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Extracted attachments are separate files (filename.md)", "content.md has pointers, not full text", "Read the .pdf.md file when you need attachment content"], "current": 3}, "done_at": "2026-02-09T06:11:25Z"}
{"id": "mise-q7j", "title": "Evaluate v1 PDF thumbnail extraction", "type": "action", "status": "open", "brief": {"why": "v1 (mcp-google-workspace) surfaces thumbnails as well as markdown for PDFs. Evaluate whether to port this logic.", "what": "## Context\n\nUser requested evaluation of v1's PDF handling which includes thumbnails, not just text extraction.\n\n## v1 Behavior (to investigate)\n\nNeed to check mcp-google-workspace for:\n1. How does v1 extract PDF thumbnails?\n2. What API/library does it use?\n3. Are these page thumbnails or embedded images?\n4. What's the quality/performance tradeoff?\n\n## Questions to Answer\n\n1. **Value**: Do PDF thumbnails add value for Claude's analysis?\n   - Charts/graphs embedded in PDFs\n   - Scanned documents with images\n   - Presentations exported to PDF\n\n2. **Feasibility**: What does extraction require?\n   - PyMuPDF (AGPL license - problematic)\n   - pdf2image + poppler (MIT, but heavy dependency)\n   - Drive thumbnail API (if available for PDFs?)\n   \n3. **Consistency**: Should PDFs match slides behavior?\n   - Slides: content.md + slide_*.png\n   - PDFs: content.md + page_*.png?\n\n4. **Cost**: Performance impact?\n   - Thumbnail generation time\n   - Storage overhead\n   - Token cost for Claude to analyze images\n\n## Research Tasks\n\n- [ ] Read v1's PDF handling code\n- [ ] Test v1 on sample PDFs\n- [ ] Compare output: v1 vs mise-en-space\n- [ ] Benchmark performance difference\n- [ ] Assess license implications\n\n## Decision Outcome\n\nAfter research, create follow-up bead:\n- If YES: \"Port v1 PDF thumbnail extraction\" with implementation plan\n- If NO: Close with rationale documented\n\n## Acceptance Criteria\n\n- [ ] v1 PDF code reviewed\n- [ ] Sample PDFs tested in both systems\n- [ ] Comparison documented (quality, speed, deps)\n- [ ] Decision made and rationale captured\n- [ ] Follow-up bead created OR this closed with \"won't do\"", "done": "When complete"}, "created_at": "2026-01-24T20:09:59.884865Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-qa6", "title": "Test hybrid PDF threshold logic", "type": "action", "status": "done", "done_at": "2026-01-25T17:39:24.848484Z", "brief": {"why": "Unit test for the <500 char fallback in fetch_pdf. Test cases: (1) markitdown returns 600 chars → no fallback, (2) markitdown returns 100 chars → Drive fallback triggered. Mock both paths.", "what": "See title", "done": "When complete"}, "created_at": "2026-01-24T19:56:12.495317Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-r0a", "title": "Extract V2.md into decisions summary", "type": "action", "status": "open", "brief": {"why": "V2.md is 466 lines of research. Extract key decisions into a digestible table format.", "what": "## Target Format\n\n| Topic | Decision | Rationale | Source |\n|-------|----------|-----------|--------|\n| Gmail HTML→MD | markitdown | 100ms vs 10s (Google Docs API) | V2.md Gmail section |\n| PDF extraction | PyMuPDF primary | 35x faster, AGPL acceptable for personal | V2.md PDF section |\n| ... | ... | ... | ... |\n\n## Location\n\nAdd to CLAUDE.md or create docs/DECISIONS.md\n\n## Why\n\nFuture Claude needs decisions quickly, not 466 lines of exploration.", "done": "When complete"}, "created_at": "2026-01-23T07:30:15.795777Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-racafe", "type": "action", "title": "Create pre-exfil test fixture", "brief": {"why": "Need email with attachment that's been exfiltrated to Drive to test pre-exfil detection logic.", "what": "1. Find email with attachment 2. Verify attachment in Email Attachments folder 3. Note thread ID, filename, Drive file ID 4. Add to fixtures", "done": "Test fixture documented with email thread ID, attachment filename, Drive file ID"}, "status": "done", "parent": "mise-4mj", "order": 3, "created_at": "2026-01-29T22:14:51Z", "created_by": "spm1001", "waiting_for": null, "done_at": "2026-02-08T18:55:04Z"}
{"id": "mise-ribiTo", "type": "outcome", "title": "Surface action items from Workspace APIs", "brief": {"why": "Action items scattered across 3 sources: (1) Tasks API (Google Tasks), (2) Activity API (comments mentioning you), (3) Assigned tasks in Docs (@mention checkboxes) — the bane of existence, buried with no central view.", "what": "1. Explore all 3 sources for action item surfacing\n2. Tasks API → sync to todoist-gtd or just surface?\n3. Activity API → filter for mentions, extract action items\n4. Docs assigned tasks → can we find these? (parse doc content for checkbox+@mention)\n5. Decide: sous-chef surfaces, pipes to todoist-gtd, or both", "done": "Clear decision on each source: ignore, surface via fetch enrichment, or pipe to todoist-gtd"}, "status": "done", "order": 19, "created_at": "2026-01-31T19:35:56Z", "created_by": "spm1001", "done_at": "2026-02-01T10:58:33Z"}
{"id": "mise-rilegu", "type": "action", "title": "Check mem indexing coverage for mise-en-space", "brief": {"why": "During Feb 8 session, mem search returned zero results for mise-en-space sessions despite them existing. Either indexer hasn't run recently or search terms need adjusting. This made decision archaeology harder than it should be.", "what": "1. Run mem status to check mise-en-space coverage 2. If under-indexed, run mem scan for this project 3. Verify that recent sessions (Jan-Feb 2026) are findable", "done": "mem search finds mise-en-space sessions reliably"}, "status": "done", "parent": "mise-3uu", "order": 11, "created_at": "2026-02-08T21:22:36Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Run mem status to check mise-en-space coverage", "If under-indexed, run mem scan for this project", "Verify that recent sessions (Jan-Feb", "are findable"], "current": 4}, "done_at": "2026-02-09T10:30:46Z"}
{"id": "mise-rohali", "type": "action", "title": "Add unit tests for charts adapter", "brief": {"why": "adapters/charts.py only has integration tests. Need mocked unit tests for get_charts_from_spreadsheet() parsing, render_charts_as_pngs(), and error handling.", "what": "Add unit tests with mocked Slides/Drive services covering: parsing, rendering, missing contentUrl, failed PNG fetch", "done": "charts adapter has unit tests, can run without real API"}, "status": "done", "parent": "mise-3uu", "order": 3, "created_at": "2026-01-29T22:14:23Z", "created_by": "spm1001", "waiting_for": null, "done_at": "2026-02-09T06:59:55Z"}
{"id": "mise-rosite", "type": "action", "title": "Pre-exfil filename matching may break with renamed files", "brief": {"why": "exfil_by_name matches Gmail attachment filename to Drive file name. But exfil script may add (1) suffixes for deduplication. Springer fixture already has this: '2026 GBP+Price+List (1).xlsx'", "what": "1. Investigate what the exfil script does to filenames 2. If it renames, add fuzzy matching (strip dedup suffixes) or match on Content Hash instead", "done": "Pre-exfil lookup finds files even when exfil script has renamed them"}, "status": "done", "parent": "mise-4mj", "order": 8, "created_at": "2026-02-08T19:17:18Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Investigate what the exfil script does to filenames", "If it renames, add fuzzy matching (strip dedup suffixes) or match on Content Hash instead"], "current": 2}, "done_at": "2026-02-08T19:34:25Z"}
{"id": "mise-rufile", "type": "action", "title": "Capture fixtures for untested adapters", "brief": {"why": "7 adapters have no fixture data: activity, charts, genai, image, office, pdf, web. Tests mock API responses but don't verify against real data shapes.", "what": "1. Capture real API responses for each adapter 2. Sanitize PII 3. Add to fixtures/ directory 4. Wire into conftest.py", "done": "Every adapter has at least one real fixture in fixtures/"}, "status": "done", "parent": "mise-3uu", "order": 10, "created_at": "2026-02-07T18:50:43Z", "created_by": "spm1001", "waiting_for": null, "done_at": "2026-02-09T07:20:08Z"}
{"id": "mise-rukola", "type": "action", "title": "fetch.py is readable at any function, not just at file scope", "brief": {"why": "tools/fetch.py is 1611 lines — 15 fetch_* functions each repeating a 20-line deposit/manifest/cues sequence. Titans review (Feb 2026): both Metis and Prometheus flagged it independently. It's the longest file by 3x and every new content type adds ~100 lines of boilerplate. The file is readable at function level (once you find the function) but unreadable at file level — you can't hold the routing logic and the deposit logic in your head simultaneously.", "what": "1. Extract a deposit_pipeline() helper that handles the repeated write_content → write_manifest → _build_cues → FetchResult sequence — the 15 fetch sites each repeat this with minor variations (comment count, email_context, warnings source). 2. Consider tools/fetch/ package with __init__.py re-exporting do_fetch, sub-modules for routing (detect_id_type, fetch_drive dispatcher), gmail (fetch_gmail, fetch_attachment), web (fetch_web, _fetch_web_pdf, _fetch_web_office), drive types (fetch_doc/sheet/slides/pdf/office/text/image/video), and cues (_build_cues, _build_email_context_metadata). External interface unchanged. 3. Run full test suite — tests import individual functions so imports must be updated or re-exported.", "done": "tools/fetch.py split into modules, no module over 400 lines, 1031 tests still pass, do_fetch still importable from tools"}, "status": "done", "parent": "mise-jy3", "order": 17, "created_at": "2026-02-09T21:16:24Z", "created_by": "spm1001", "waiting_for": null, "done_at": "2026-02-09T22:27:42Z"}
{"id": "mise-siJoRo", "type": "action", "title": "Web fetch handles hostile sites gracefully", "brief": {"why": "Some websites actively resist extraction — infinite redirects, tarpit responses, massive payloads, misleading Content-Types. Current web.py has timeouts but no systematic defence. A hostile site can hang or OOM the fetch.", "what": "1. Catalog hostile patterns seen in the wild (redirect loops, tarpits, size bombs, soft auth walls, CAPTCHA) 2. Add/verify defences for each (timeouts, size limits, redirect caps, clear detection) 3. Return structured error messages per pattern", "done": "Each hostile pattern produces a clear, actionable error message instead of hang, OOM, or corrupted output"}, "status": "open", "order": 10, "created_at": "2026-02-01T19:08:36Z", "created_by": "spm1001", "parent": "mise-jy3", "waiting_for": null}
{"id": "mise-siLugo", "type": "action", "title": "Calendar context in search results", "brief": {"why": "Docs don't exist in isolation. Meeting context explains why a doc matters — who was in the meeting, when it happened, what other docs were linked.", "what": "1. Add source='calendar' option to search, or enrich Drive results with calendar context 2. Query calendar.events() for recent events with attachments 3. Cross-reference file IDs with search results 4. Add meeting context to result metadata", "done": "Search results include meeting context when available"}, "status": "open", "parent": "mise-jy3", "order": 5, "created_at": "2026-02-01T10:59:41Z", "created_by": "spm1001", "waiting_for": null}
{"id": "mise-sireho", "type": "action", "title": "Cap files list for slides deposits", "brief": {"why": "cues.files lists every file in the deposit folder. A 43-slide deck with thumbnails produces ~45 filenames (~200 tokens). This is noisy and the individual slide_XX.png names add no decision value.", "what": "1. In _build_cues, detect thumbnail files by pattern (slide_*.png) 2. Replace individual filenames with summary: 'slide_01.png ... slide_43.png (43 thumbnails)' or just add thumbnail_count 3. Keep non-thumbnail files listed individually", "done": "Slides fetch cues.files is compact regardless of slide count"}, "status": "done", "parent": "mise-jy3", "order": 14, "created_at": "2026-02-09T20:44:22Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["In _build_cues, detect thumbnail files by pattern (slide_*.png)", "Replace individual filenames with summary: 'slide_01.png ... slide_43.png (43 thumbnails)' or just add thumbnail_count", "Keep non-thumbnail files listed individually"], "current": 3}, "done_at": "2026-02-09T22:45:14Z"}
{"id": "mise-sitovi", "type": "action", "title": "Create tool returns useful post-action signals", "brief": {"why": "Fetch and search now surface cues/preview so Claude doesn't need to read manifest.json. Create has no equivalent — after creating a doc, Claude doesn't know sharing status, folder location, or whether the doc was actually created where expected.", "what": "1. Audit what create currently returns 2. Identify what signals would change Claude's next action (share link? open in browser? move to folder?) 3. Design cues block for create responses 4. Implement and test", "done": "Create response includes actionable signals — at minimum: web_link, folder_name, sharing_status"}, "status": "open", "parent": "mise-hijute", "order": 3, "created_at": "2026-02-09T20:53:36Z", "created_by": "spm1001", "waiting_for": null}
{"id": "mise-sujuKo", "type": "action", "title": "Add raw text unit tests", "brief": {"why": "Raw text handling (_is_raw_text, _format_raw_text) works but lacks explicit unit test coverage.", "what": "Add TestRawTextHandling class to test_web.py with tests for Content-Type detection, URL extension detection, and formatting for each file type.", "done": "Unit tests cover all raw text code paths"}, "status": "done", "order": 9, "created_at": "2026-02-01T15:23:28Z", "created_by": "spm1001", "parent": "mise-3uu", "waiting_for": null, "tactical": {"steps": ["Understand raw text code paths (_is_raw_text, _format_raw_text)", "Write TestRawTextHandling in test_web.py", "Run tests, verify coverage"], "current": 3}, "done_at": "2026-02-09T06:55:56Z"}
{"id": "mise-tagemu", "type": "outcome", "title": "Apps Script email extractor pipeline", "brief": {"why": "Email attachment extraction (Gmail → Drive) is infrastructure that runs in Google, separate from mise's codebase. Currently lives in mcp-google-workspace being wound down.", "what": "1. Port apps-script from v1 (gelopa) 2. Parameterize year functions (Recebe)", "done": "apps-script/ in mise-en-space, deployable, adding a new year is config-only"}, "status": "open", "order": 26, "created_at": "2026-02-08T19:22:07Z", "created_by": "spm1001"}
{"id": "mise-tisatu", "type": "action", "title": "Guard against empty thread_id in Gmail batch callback", "brief": {"why": "Gmail ordering fix (cecuzu) uses results_by_id dict keyed by thread_id. If batch callback fires with empty string id, result is stored under '' and silently dropped from reorder. Edge case but violates 'no silent data loss' principle.", "what": "1. Add guard in handle_thread_response: skip if thread_id is empty 2. Add warning when thread_id missing 3. Test: callback with empty id produces warning, not silent drop", "done": "Empty thread_id produces warning, doesn't silently vanish"}, "status": "open", "parent": "mise-jy3", "order": 21, "created_at": "2026-02-09T23:20:07Z", "created_by": "spm1001", "waiting_for": null}
{"id": "mise-tivoBu", "type": "action", "title": "Prototype pattern-based structure detection", "brief": {"why": "LLM distillation has cost; pattern matching might handle 80% case cheaply", "what": "Regex/heuristics for common patterns: 'Action Items:', '[ ]', 'Decision:', '@mentions'", "done": "Have extraction that finds action items and decisions without LLM call"}, "status": "open", "parent": "mise-fetifo", "order": 3, "created_at": "2026-01-30T12:49:23Z", "created_by": "spm1001", "waiting_for": null}
{"id": "mise-tld", "title": "Wire resources — self-documenting capabilities", "type": "action", "status": "done", "done_at": "2026-01-25T17:48:57.200251Z", "brief": {"why": "MCP resources that expose dynamic API info: import/export formats, quotas, patterns.", "what": "## From v1\n\nworkspace://capabilities/drive/import-formats  → What can be imported\nworkspace://capabilities/drive/export-formats  → What can be exported\nworkspace://quotas/drive/storage               → User's storage limits\nworkspace://patterns/...                       → Usage patterns\n\n## Why Useful\n\nClaude can read these to discover what's possible without external docs.\nDynamic = fetched from actual API (about.get), not static.\n\n## Simpler for v2?\n\nCould consolidate into fewer resources:\n- workspace://capabilities → all format info\n- workspace://help/{topic} → patterns + usage\n\nOr just rely on help() tool and skip resources.\n\n## Acceptance Criteria\n\n- [ ] Decide: resources vs expanded help() tool\n- [ ] If resources: wire import/export formats\n- [ ] Dynamic content from API (not static)", "done": "When complete"}, "created_at": "2026-01-23T07:26:49.012371Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-tuguzi", "type": "outcome", "title": "Figured out mise skill strategy", "brief": {"why": "v1 skill exists but references dead tools; need to decide whether mise needs its own skill or none at all", "what": "1. Week-long probe of MCP-only usage 2. Decide: no skill / minimal skill / port v1 3. Archive or replace v1 skill", "done": "v1 skill archived or replaced; decision documented"}, "status": "done", "order": 2, "created_at": "2026-02-01T10:58:09Z", "created_by": "spm1001", "done_at": "2026-02-09T15:23:17Z"}
{"id": "mise-udh", "title": "Stream large files to disk instead of memory", "type": "action", "status": "done", "done_at": "2026-01-25T17:16:11.1059Z", "brief": {"why": "Currently loads entire files into memory (pdf_bytes = download_file()). User reports gigabyte PPTXs at ITV. Need streaming pattern to handle large files without OOM.", "what": "## Problem\nPDF/Office adapters load entire files into RAM before processing.\nThis fails for large files (user reports gigabyte PPTXs).\n\n## Approach Options\n1. **Stream download to temp file** — Download in chunks to disk, then process\n2. **Lazy loading** — Only load chunks as needed during extraction\n3. **File size check first** — Fail fast with error for files over threshold\n\n## Affected Files\n- adapters/pdf.py: `extract_pdf_content(file_bytes: bytes, ...)`\n- adapters/office.py: `extract_office_content(file_bytes: bytes, ...)`\n- adapters/drive.py: `download_file()` returns bytes\n\n## Acceptance Criteria\n- [ ] Files over 100MB don't cause OOM\n- [ ] Streaming pattern documented\n- [ ] Tests with large file simulation", "done": "When complete"}, "created_at": "2026-01-25T16:59:40.853018Z", "created_by": "spm1001", "order": 1, "waiting_for": null}
{"id": "mise-v79", "title": "Refactor retry decorator duplication", "type": "action", "status": "done", "done_at": "2026-01-24T20:34:20.265849Z", "brief": {"why": "async_wrapper and sync_wrapper in retry.py are nearly identical. DRY violation.", "what": "## Problem\n\nIn retry.py lines 143-204:\n- `async_wrapper()` (lines 143-174)\n- `sync_wrapper()` (lines 177-204)\n\nBoth have identical:\n- Retry loop structure\n- Exponential backoff calculation\n- Jitter application\n- Exception handling logic\n\nOnly difference: `await func(...)` vs `func(...)`\n\n## Approach\n\nExtract common logic into helper:\n\n```python\ndef _calculate_delay(attempt: int, delay_ms: int, jitter_ms: int) -> float:\n    \"\"\"Calculate delay with exponential backoff and jitter.\"\"\"\n    base = delay_ms * (2 ** attempt) / 1000\n    jitter = random.uniform(0, jitter_ms / 1000)\n    return base + jitter\n\ndef _should_retry(exception: Exception, retryable_errors: tuple) -> bool:\n    \"\"\"Determine if exception is retryable.\"\"\"\n    # Check HTTP status codes, error types, etc.\n```\n\nThen both wrappers become thin:\n```python\nasync def async_wrapper(*args, **kwargs):\n    for attempt in range(max_attempts):\n        try:\n            return await func(*args, **kwargs)\n        except retryable_errors as e:\n            if not _should_retry(e, retryable_errors):\n                raise\n            delay = _calculate_delay(attempt, delay_ms, jitter_ms)\n            await asyncio.sleep(delay)\n    raise\n```\n\n## Acceptance Criteria\n\n- [ ] Common retry logic extracted\n- [ ] async_wrapper uses helper functions\n- [ ] sync_wrapper uses helper functions\n- [ ] Tests still pass\n- [ ] No behavior change (just refactor)", "done": "When complete"}, "created_at": "2026-01-24T20:10:24.232062Z", "created_by": "spm1001", "order": 1, "parent": "mise-52d", "waiting_for": null}
{"id": "mise-voSovu", "type": "action", "title": "Embed extracted PDF content in content.md", "brief": {"why": "Currently PDFs are deposited separately; Claude must Read them explicitly. Should embed text like Drive PDFs.", "what": "After extracting PDF attachment, append extracted markdown to thread content.md (like we do for Drive PDFs). Keep raw PDF file for reference.", "done": "content.md includes inline PDF text for all extracted attachments"}, "status": "done", "parent": "mise-4mj", "order": 7, "created_at": "2026-02-01T10:59:03Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Trace current deposit flow to understand where content.md is written", "Append extracted attachment content to thread content.md after extraction", "Add tests for inline embedding", "Verify with full test suite"], "current": 4}, "done_at": "2026-02-08T19:41:33Z"}
{"id": "mise-votiru", "type": "action", "title": "Cues work end-to-end in live fetch", "brief": {"why": "Cues (6af6745) shipped based on design feedback but haven't been verified with a real fetch against the running MCP. Response shape may differ from spec.", "what": "1. Start mise MCP locally 2. Run a fetch against a known Drive doc 3. Verify cues block contains files, open_comment_count, warnings, content_length, email_context 4. Run a Gmail fetch and verify participants, has_attachments, date_range appear 5. Run a search and verify preview block with top 3 per source", "done": "All three tool types (fetch doc, fetch gmail, search) return cues/preview blocks matching the shipped spec"}, "status": "done", "parent": "mise-jy3", "order": 16, "created_at": "2026-02-09T20:53:30Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Start mise MCP locally", "Run a fetch against a known Drive doc", "Verify cues block contains files, open_comment_count, warnings, content_length, email_context", "Run a Gmail fetch and verify participants, has_attachments, date_range appear", "Run a search and verify preview block with top 3 per source"], "current": 5}, "done_at": "2026-02-09T22:49:59Z"}
{"id": "mise-w6f", "title": "Render Sheets charts as PNGs via Slides API", "type": "action", "status": "done", "done_at": "2026-01-25T20:42:03.58269Z", "brief": {"why": "When fetching spreadsheets with charts, render chart images by embedding in a temp Slides presentation, fetching contentUrl, and saving as PNGs. This makes chart content visible to Claude.", "what": "## Decisions (Jan 2026)\n\n1. **Default on** — Always render charts when present\n2. **Per-fetch presentation** — Create/cleanup per fetch (not persistent)\n3. **All charts** — Both chart sheets (sheetType=OBJECT) AND embedded charts on GRID sheets\n\n## Approach\n\nFrom itv-slides-formatter research (contentUrl-resolution.md, explore_charts.py):\n\n1. Get spreadsheet metadata including `sheets[].charts[]` array\n2. For each chart (floating or sheet chart):\n   - Insert into temp Slides presentation via `createSheetsChart`\n   - Get `contentUrl` from resulting pageElement\n   - Fetch PNG via HTTP GET\n   - Save to deposit folder\n3. Clean up temp presentation\n\n## Timing Expectations\n\n- ~500ms per chart (similar to slides thumbnails)\n- Spreadsheet with 5 charts ≈ 2.5s additional latency\n- Document in manifest: `chart_count`, `chart_fetch_time_ms`\n\n## Test Fixture\n\nhttps://docs.google.com/spreadsheets/d/1UlWoEsfjzqbuS_tKD6Drm4wmbPLeGOKWVBVip5AI-xw/edit\n\n## Deposit Structure\n\n```\nmise-fetch/sheet--budget-2026--abc123/\n├── manifest.json\n├── content.md          # Grid data as markdown tables  \n├── chart_1.png         # Rendered chart images\n├── chart_2.png\n└── charts.json         # Metadata: title, type, source ranges\n```\n\n## Also Needed\n\n- Filter GRID sheets for values (mise-bpm) — but now as part of this work\n- Handle sheetType=OBJECT (chart sheets) by rendering, not skipping\n\n## Acceptance Criteria\n\n- [ ] Charts extracted from both GRID sheets and chart sheets\n- [ ] PNG files saved to deposit folder\n- [ ] charts.json has metadata (title, type, chartId)\n- [ ] Timing tests: fetch with/without charts\n- [ ] Test against fixture spreadsheet", "done": "When complete"}, "created_at": "2026-01-25T20:13:34.882308Z", "created_by": "spm1001", "order": 1, "parent": "mise-6kh", "waiting_for": null}
{"id": "mise-waguwe", "type": "action", "title": "Third verb scaffolding: create becomes do(operation=...)", "brief": {"why": "Current MCP has 'create' as a standalone tool. The do-verb design (Feb 2026) replaces it with do(operation=create|move|rename|share). Need the plumbing before any operation beyond create can land.", "what": "1. Rename create tool to do in server.py 2. Add operation param (default='create' for backwards compat) 3. Route operation=create to existing do_create 4. Update MCP tool description and docstring 5. Update tests", "done": "do(operation='create') works identically to old create tool; new operations can be added by wiring"}, "status": "open", "parent": "mise-hijute", "order": 1, "created_at": "2026-02-09T23:17:15Z", "created_by": "spm1001", "waiting_for": null}
{"id": "mise-weduje", "type": "outcome", "title": "Faster mise operations", "brief": {"why": "Benchmarks (Feb 2026) show several paths where latency could be halved. Search-both at 2.3s is the most impactful since it's the default mode. Slides and Office are slower but constrained by Google APIs.", "what": "Parallel search, investigate slides batch alternatives, profile Office conversion pipeline", "done": "Search-both under 1.5s. Slides and Office paths profiled with clear picture of what's API-bound vs what we control."}, "status": "done", "order": 27, "created_at": "2026-02-09T06:36:57Z", "created_by": "spm1001", "done_at": "2026-02-09T14:15:30Z"}
{"id": "mise-wiBoKe", "type": "action", "title": "Add attachments/drive_links to Gmail FetchResult.metadata", "brief": {"why": "Currently only in markdown text, need structured data for programmatic follow-up", "what": "Extract attachment list and drive_links to FetchResult.metadata dict", "done": "Gmail fetch returns metadata with attachments and drive_links arrays"}, "status": "done", "parent": "mise-cunufu", "order": 4, "created_at": "2026-01-29T21:12:35Z", "created_by": "spm1001", "waiting_for": null, "done_at": "2026-01-29T21:14:32Z"}
{"id": "mise-wijupo", "type": "action", "title": "Blind test search preview", "brief": {"why": "Search preview was designed based on test Claude's jq struggles but never validated live. Fetch cues were validated by blind test; search preview was not. Need to verify preview actually eliminates field guessing and jq triage step.", "what": "1. Give fresh Claude a search-heavy prompt (multi-source, needs filtering) 2. Observe: does it use preview to pick what to fetch? Does it skip jq? 3. Check if top 3 is enough or if it still reads deposited file", "done": "Live test confirms preview reduces or eliminates jq triage calls"}, "status": "done", "parent": "mise-jy3", "order": 15, "created_at": "2026-02-09T20:44:25Z", "created_by": "spm1001", "waiting_for": null, "done_at": "2026-02-09T23:07:48Z"}
{"id": "mise-wodufo", "type": "action", "title": "Detect exfil'd files and expose email context", "brief": {"why": "When file is in Email Attachments folder with Message ID, surface email context", "what": "Parse description for Message ID, detect folder membership, add email_context to results", "done": "Drive results show email linkage when available"}, "status": "done", "parent": "mise-cunufu", "order": 3, "created_at": "2026-01-29T21:12:30Z", "created_by": "spm1001", "waiting_for": null, "done_at": "2026-01-29T21:14:13Z"}
{"id": "mise-wonaru", "type": "action", "title": "Evaluate v1 PDF thumbnail extraction", "brief": {"why": "v1 surfaces thumbnails + markdown for PDFs. Need to evaluate if worth porting. PDFs with charts/graphs/scans may benefit from visual extraction.", "what": "1. Review v1 PDF code 2. Test on sample PDFs 3. Compare output quality/speed/deps 4. Assess license implications (PyMuPDF=AGPL, pdf2image=MIT) 5. Decide: port or close", "done": "v1 PDF code reviewed, samples tested, comparison documented, decision made with rationale"}, "status": "open", "parent": "mise-jy3", "order": 2, "created_at": "2026-01-29T22:14:29Z", "created_by": "spm1001", "waiting_for": null}
{"id": "mise-wudutu", "type": "action", "title": "Scoped titans rerun on cues code path", "brief": {"why": "Feb 2026 titans review covered the whole codebase (broad-but-shallow). After mise-votiru validates cues live, a focused re-review on just the cues/preview code path (tools/fetch.py _build_cues, models.py FetchResult/SearchResult, and the 15 fetch call sites) would go deeper on the newest, least-battle-tested code.", "what": "1. Complete mise-votiru first (live validation) 2. Run titans scoped to: _build_cues, _build_email_context_metadata, FetchResult.to_dict, SearchResult._build_preview, and their call sites 3. Act on findings", "done": "Focused review complete, findings addressed or filed"}, "status": "done", "parent": "mise-jy3", "order": 19, "created_at": "2026-02-09T21:21:16Z", "created_by": "spm1001", "waiting_for": null, "done_at": "2026-02-09T23:15:31Z"}
{"id": "mise-x2r", "title": "Add logging to extractors", "type": "action", "status": "done", "done_at": "2026-01-23T17:51:06.062342Z", "brief": {"why": "Extractors are pure functions with zero visibility. When extraction fails silently or produces garbage, no trace of what happened. Add key log points: DEBUG for processing counts, WARNING for unknown elements or truncation.", "what": "See title", "done": "When complete"}, "created_at": "2026-01-23T14:50:12.392463Z", "created_by": "spm1001", "order": 1, "waiting_for": null}
{"id": "mise-zapeZo", "type": "action", "title": "Prototype LLM distillation for one meeting note", "brief": {"why": "Test whether simple prompt can extract decisions/actions/key-points reliably", "what": "Prompt Sonnet with raw meeting note, evaluate output quality and token cost", "done": "Have sample distillation with quality notes and cost estimate"}, "status": "open", "parent": "mise-fetifo", "order": 2, "created_at": "2026-01-30T12:49:22Z", "created_by": "spm1001", "waiting_for": null}
{"id": "mise-zavizi", "type": "action", "title": "Subagent-test the mise skill", "brief": {"why": "Rewritten mise skill (CSO 91) passed lint and manual review but has no real-world validation. Subagent testing reveals behavioural gaps that reading can't — does a test Claude actually follow the workflow, use base_path, check comments?", "what": "1. Run skill-forge test_skill.py against mise skill 2. Review test Claude behaviour with skill loaded 3. Fix gaps revealed by testing", "done": "Test Claude correctly loads skill, follows post-fetch checklist, uses base_path on fetch/search"}, "status": "done", "parent": null, "order": 4, "created_at": "2026-02-09T15:48:38Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Run skill-forge test_skill.py against mise skill", "Review test Claude behaviour with skill loaded", "Fix gaps revealed by testing"], "current": 3}, "done_at": "2026-02-09T20:30:53Z"}
{"id": "mise-zetoka", "type": "action", "title": "Profile Office conversion pipeline (DOCX 9s, XLSX 6s)", "brief": {"why": "Office files are the slowest fetch path (DOCX ~9s, XLSX ~6s). The pipeline is upload→convert→export→delete — unclear which step dominates. Can't optimise what you haven't measured.", "what": "1. Add per-step timing to conversion.py (upload, convert, export, cleanup) 2. Run against DOCX and XLSX test files 3. Document which step dominates 4. If upload dominates, investigate streaming upload; if convert, nothing to do (server-side)", "done": "Per-step timing data showing where the 9s goes. Filed actions for any steps we control, or documented that it's API-bound."}, "status": "done", "parent": "mise-weduje", "order": 2, "created_at": "2026-02-09T06:37:09Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Add per-step timing to conversion.py (upload, convert, export, cleanup)", "Run against DOCX and XLSX test files", "Document which step dominates", "If upload dominates, investigate streaming upload; if convert, nothing to do (server-side)"], "current": 4}, "done_at": "2026-02-09T14:15:22Z"}
{"id": "mise-zezuva", "type": "outcome", "title": "Activity API search source", "brief": {"why": "Action items discovery needs efficient cross-file search. Activity API can find all comment events in one call vs N+1 queries through comments endpoint.", "what": "1. Add source='activity' option to search tool\n2. Query activity.query(filter='detail.action_detail_case:COMMENT')\n3. Filter to mentionedUsers containing current user\n4. Return files with open action items", "done": "search(source='activity') returns files with action items for current user"}, "status": "done", "order": 13, "created_at": "2026-01-31T17:49:05Z", "created_by": "spm1001", "done_at": "2026-02-01T10:58:33Z"}
{"id": "mise-zisiwe", "type": "action", "title": "Stream large web PDFs to temp file", "brief": {"why": "Web PDF fetch loads entire response.content into memory. A 200MB PDF kills the process. Drive path has streaming (via STREAMING_THRESHOLD_BYTES); web path doesn't.", "what": "1. Use httpx streaming (client.stream) in adapters/web.py for binary content types 2. Check Content-Length header — if over threshold, stream to temp file and set raw_bytes=None, add a temp_path field to WebData 3. Update _fetch_web_pdf in tools/fetch.py to handle both raw_bytes and temp_path 4. Add test with mocked large response", "done": "Web PDF fetch for files >50MB streams to temp without OOM. Unit test confirms temp_path path. Existing small-PDF path unchanged."}, "status": "done", "parent": "mise-jy3", "order": 8, "created_at": "2026-02-07T16:17:50Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Use httpx streaming (client.stream) in adapters/web.py for binary content types", "Check Content-Length header — if over threshold, stream to temp file and set raw_bytes=None, add a temp_path field to WebData", "Update _fetch_web_pdf in tools/fetch.py to handle both raw_bytes and temp_path", "Add test with mocked large response"], "current": 4}, "done_at": "2026-02-07T16:32:53Z"}
{"id": "mise-zujapu", "type": "action", "title": "tools/fetch.py test coverage", "brief": {"why": "tools/fetch.py is 64% covered (215 uncovered lines) — the last significant gap. All adapters, extractors, and workspace are at 100%. fetch.py is 1400 lines of orchestration that exercises everything underneath.", "what": "1. Read fetch.py top-to-bottom mapping all uncovered paths 2. Write validation/routing tests (detect_id_type, URL parsing) 3. Write fetch_drive orchestration tests 4. Write fetch_gmail orchestration tests 5. Write fetch_web orchestration tests 6. Target 90%+ coverage", "done": "uv run pytest shows tools/fetch.py at 90%+ coverage"}, "status": "done", "parent": "mise-3uu", "order": 15, "created_at": "2026-02-09T08:09:31Z", "created_by": "spm1001", "waiting_for": null, "tactical": {"steps": ["Read fetch.py top-to-bottom mapping all uncovered paths", "Write validation/routing tests (detect_id_type, URL parsing)", "Write fetch_drive orchestration tests", "Write fetch_gmail orchestration tests", "Write fetch_web orchestration tests", "Target 90%+ coverage"], "current": 6}, "done_at": "2026-02-09T08:33:04Z"}
